Attaching to 221_zk_1, 221_kafka_1, 221_connect_1
zk_1       | ZooKeeper JMX enabled by default
zk_1       | Using config: /conf/zoo.cfg
zk_1       | 2019-07-01 12:38:53,482 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /conf/zoo.cfg
zk_1       | 2019-07-01 12:38:53,486 [myid:] - INFO  [main:DatadirCleanupManager@78] - autopurge.snapRetainCount set to 3
zk_1       | 2019-07-01 12:38:53,487 [myid:] - INFO  [main:DatadirCleanupManager@79] - autopurge.purgeInterval set to 0
zk_1       | 2019-07-01 12:38:53,487 [myid:] - INFO  [main:DatadirCleanupManager@101] - Purge task is not scheduled.
zk_1       | 2019-07-01 12:38:53,488 [myid:] - WARN  [main:QuorumPeerMain@116] - Either no config or no quorum defined in config, running  in standalone mode
zk_1       | 2019-07-01 12:38:53,499 [myid:] - INFO  [main:QuorumPeerConfig@136] - Reading configuration from: /conf/zoo.cfg
zk_1       | 2019-07-01 12:38:53,499 [myid:] - INFO  [main:ZooKeeperServerMain@98] - Starting server
zk_1       | 2019-07-01 12:38:53,505 [myid:] - INFO  [main:Environment@100] - Server environment:zookeeper.version=3.4.14-4c25d480e66aadd371de8bd2fd8da255ac140bcf, built on 03/06/2019 16:18 GMT
zk_1       | 2019-07-01 12:38:53,506 [myid:] - INFO  [main:Environment@100] - Server environment:host.name=115efe7e558e
zk_1       | 2019-07-01 12:38:53,506 [myid:] - INFO  [main:Environment@100] - Server environment:java.version=1.8.0_201
zk_1       | 2019-07-01 12:38:53,506 [myid:] - INFO  [main:Environment@100] - Server environment:java.vendor=Oracle Corporation
zk_1       | 2019-07-01 12:38:53,506 [myid:] - INFO  [main:Environment@100] - Server environment:java.home=/usr/lib/jvm/java-1.8-openjdk/jre
zk_1       | 2019-07-01 12:38:53,506 [myid:] - INFO  [main:Environment@100] - Server environment:java.class.path=/zookeeper-3.4.14/bin/../zookeeper-server/target/classes:/zookeeper-3.4.14/bin/../build/classes:/zookeeper-3.4.14/bin/../zookeeper-server/target/lib/*.jar:/zookeeper-3.4.14/bin/../build/lib/*.jar:/zookeeper-3.4.14/bin/../lib/slf4j-log4j12-1.7.25.jar:/zookeeper-3.4.14/bin/../lib/slf4j-api-1.7.25.jar:/zookeeper-3.4.14/bin/../lib/netty-3.10.6.Final.jar:/zookeeper-3.4.14/bin/../lib/log4j-1.2.17.jar:/zookeeper-3.4.14/bin/../lib/jline-0.9.94.jar:/zookeeper-3.4.14/bin/../lib/audience-annotations-0.5.0.jar:/zookeeper-3.4.14/bin/../zookeeper-3.4.14.jar:/zookeeper-3.4.14/bin/../zookeeper-server/src/main/resources/lib/*.jar:/conf:
zk_1       | 2019-07-01 12:38:53,506 [myid:] - INFO  [main:Environment@100] - Server environment:java.library.path=/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64/server:/usr/lib/jvm/java-1.8-openjdk/jre/lib/amd64:/usr/lib/jvm/java-1.8-openjdk/jre/../lib/amd64:/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
zk_1       | 2019-07-01 12:38:53,507 [myid:] - INFO  [main:Environment@100] - Server environment:java.io.tmpdir=/tmp
zk_1       | 2019-07-01 12:38:53,507 [myid:] - INFO  [main:Environment@100] - Server environment:java.compiler=<NA>
kafka_1    | + '[' -n '' ']'
kafka_1    | + '[' -n '' ']'
zk_1       | 2019-07-01 12:38:53,508 [myid:] - INFO  [main:Environment@100] - Server environment:os.name=Linux
zk_1       | 2019-07-01 12:38:53,508 [myid:] - INFO  [main:Environment@100] - Server environment:os.arch=amd64
kafka_1    | ++ grep '\sd8bc390657d9$' /etc/hosts
kafka_1    | ++ awk '{print $1}'
kafka_1    | ++ head -n 1
kafka_1    | + IP=172.21.0.3
kafka_1    | + '[' -z zk:2181 ']'
kafka_1    | + cat /kafka/config/server.properties.template
kafka_1    | + sed -e 's|{{KAFKA_ADVERTISED_HOST_NAME}}|kafka|g' -e 's|{{KAFKA_ADVERTISED_PORT}}|9092|g' -e 's|{{KAFKA_AUTO_CREATE_TOPICS_ENABLE}}|true|g' -e 's|{{KAFKA_BROKER_ID}}|0|g' -e 's|{{KAFKA_DEFAULT_REPLICATION_FACTOR}}|1|g' -e 's|{{KAFKA_DELETE_TOPIC_ENABLE}}|false|g' -e 's|{{KAFKA_GROUP_MAX_SESSION_TIMEOUT_MS}}|300000|g' -e 's|{{KAFKA_INTER_BROKER_PROTOCOL_VERSION}}|0.10.2.1|g' -e 's|{{KAFKA_LOG_MESSAGE_FORMAT_VERSION}}|0.10.2.1|g' -e 's|{{KAFKA_LOG_RETENTION_HOURS}}|168|g' -e 's|{{KAFKA_NUM_PARTITIONS}}|1|g' -e 's|{{KAFKA_PORT}}|9092|g' -e 's|{{ZOOKEEPER_CHROOT}}|/broker-0|g' -e 's|{{ZOOKEEPER_CONNECTION_STRING}}|zk:2181|g' -e 's|{{ZOOKEEPER_CONNECTION_TIMEOUT_MS}}|10000|g' -e 's|{{ZOOKEEPER_SESSION_TIMEOUT_MS}}|10000|g' -e 's|{{KAFKA_MESSAGE_MAX_BYTES}}|1000012|g' -e 's|{{KAFKA_REPLICA_FETCH_MAX_BYTES}}|1048576|g'
zk_1       | 2019-07-01 12:38:53,508 [myid:] - INFO  [main:Environment@100] - Server environment:os.version=4.9.125-linuxkit
connect_1  | [docker-entrypoint.sh] (WARN) : EMPTY ENV 'CONNECT_REST_ADVERTISED_HOST_NAME'
connect_1  | [docker-entrypoint.sh] (WARN) : EMPTY ENV 'CONNECT_REST_ADVERTISED_PORT'
connect_1  |
connect_1  | [start-connect.sh] (INFO) : Starting...
kafka_1    | + '[' -z ']'
kafka_1    | + KAFKA_JMX_OPTS=-Dcom.sun.management.jmxremote=true
kafka_1    | + KAFKA_JMX_OPTS='-Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false'
kafka_1    | + KAFKA_JMX_OPTS='-Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false'
kafka_1    | + KAFKA_JMX_OPTS='-Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.rmi.port=7203'
kafka_1    | + KAFKA_JMX_OPTS='-Dcom.sun.management.jmxremote=true -Dcom.sun.management.jmxremote.authenticate=false -Dcom.sun.management.jmxremote.ssl=false -Dcom.sun.management.jmxremote.rmi.port=7203 -Djava.rmi.server.hostname=kafka '
kafka_1    | + export KAFKA_JMX_OPTS
kafka_1    | + echo 'Starting kafka'
kafka_1    | + exec /kafka/bin/kafka-server-start.sh /kafka/config/server.properties
kafka_1    | Starting kafka
zk_1       | 2019-07-01 12:38:53,509 [myid:] - INFO  [main:Environment@100] - Server environment:user.name=zookeeper
zk_1       | 2019-07-01 12:38:53,509 [myid:] - INFO  [main:Environment@100] - Server environment:user.home=/home/zookeeper
zk_1       | 2019-07-01 12:38:53,509 [myid:] - INFO  [main:Environment@100] - Server environment:user.dir=/zookeeper-3.4.14
zk_1       | 2019-07-01 12:38:53,517 [myid:] - INFO  [main:ZooKeeperServer@836] - tickTime set to 2000
zk_1       | 2019-07-01 12:38:53,517 [myid:] - INFO  [main:ZooKeeperServer@845] - minSessionTimeout set to -1
zk_1       | 2019-07-01 12:38:53,517 [myid:] - INFO  [main:ZooKeeperServer@854] - maxSessionTimeout set to -1
zk_1       | 2019-07-01 12:38:53,528 [myid:] - INFO  [main:ServerCnxnFactory@117] - Using org.apache.zookeeper.server.NIOServerCnxnFactory as server connection factory
zk_1       | 2019-07-01 12:38:53,535 [myid:] - INFO  [main:NIOServerCnxnFactory@89] - binding to port 0.0.0.0/0.0.0.0:2181
zk_1       | 2019-07-01 12:38:56,720 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@222] - Accepted socket connection from /172.21.0.3:46170
kafka_1    | [2019-07-01 12:38:56,529] INFO KafkaConfig values:
kafka_1    |    advertised.host.name = kafka
kafka_1    |    advertised.listeners = null
kafka_1    |    advertised.port = 9092
kafka_1    |    authorizer.class.name =
kafka_1    |    auto.create.topics.enable = true
kafka_1    |    auto.leader.rebalance.enable = true
kafka_1    |    background.threads = 10
kafka_1    |    broker.id = 0
kafka_1    |    broker.id.generation.enable = true
kafka_1    |    broker.rack = null
kafka_1    |    compression.type = producer
kafka_1    |    connections.max.idle.ms = 600000
kafka_1    |    controlled.shutdown.enable = true
kafka_1    |    controlled.shutdown.max.retries = 3
kafka_1    |    controlled.shutdown.retry.backoff.ms = 5000
kafka_1    |    controller.socket.timeout.ms = 30000
kafka_1    |    create.topic.policy.class.name = null
kafka_1    |    default.replication.factor = 1
kafka_1    |    delete.topic.enable = false
kafka_1    |    fetch.purgatory.purge.interval.requests = 1000
kafka_1    |    group.max.session.timeout.ms = 300000
kafka_1    |    group.min.session.timeout.ms = 6000
kafka_1    |    host.name =
kafka_1    |    inter.broker.listener.name = null
kafka_1    |    inter.broker.protocol.version = 0.10.2.1
kafka_1    |    leader.imbalance.check.interval.seconds = 300
kafka_1    |    leader.imbalance.per.broker.percentage = 10
kafka_1    |    listener.security.protocol.map = SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,TRACE:TRACE,SASL_SSL:SASL_SSL,PLAINTEXT:PLAINTEXT
kafka_1    |    listeners = null
kafka_1    |    log.cleaner.backoff.ms = 15000
kafka_1    |    log.cleaner.dedupe.buffer.size = 134217728
kafka_1    |    log.cleaner.delete.retention.ms = 86400000
kafka_1    |    log.cleaner.enable = true
kafka_1    |    log.cleaner.io.buffer.load.factor = 0.9
kafka_1    |    log.cleaner.io.buffer.size = 524288
kafka_1    |    log.cleaner.io.max.bytes.per.second = 1.7976931348623157E308
kafka_1    |    log.cleaner.min.cleanable.ratio = 0.5
kafka_1    |    log.cleaner.min.compaction.lag.ms = 0
kafka_1    |    log.cleaner.threads = 1
kafka_1    |    log.cleanup.policy = [delete]
kafka_1    |    log.dir = /data
kafka_1    |    log.dirs = /data
kafka_1    |    log.flush.interval.messages = 9223372036854775807
kafka_1    |    log.flush.interval.ms = null
kafka_1    |    log.flush.offset.checkpoint.interval.ms = 60000
kafka_1    |    log.flush.scheduler.interval.ms = 9223372036854775807
kafka_1    |    log.index.interval.bytes = 4096
kafka_1    |    log.index.size.max.bytes = 10485760
kafka_1    |    log.message.format.version = 0.10.2.1
kafka_1    |    log.message.timestamp.difference.max.ms = 9223372036854775807
kafka_1    |    log.message.timestamp.type = CreateTime
kafka_1    |    log.preallocate = false
kafka_1    |    log.retention.bytes = -1
kafka_1    |    log.retention.check.interval.ms = 300000
kafka_1    |    log.retention.hours = 168
kafka_1    |    log.retention.minutes = null
kafka_1    |    log.retention.ms = null
kafka_1    |    log.roll.hours = 168
kafka_1    |    log.roll.jitter.hours = 0
kafka_1    |    log.roll.jitter.ms = null
kafka_1    |    log.roll.ms = null
kafka_1    |    log.segment.bytes = 1073741824
kafka_1    |    log.segment.delete.delay.ms = 60000
kafka_1    |    max.connections.per.ip = 2147483647
kafka_1    |    max.connections.per.ip.overrides =
kafka_1    |    message.max.bytes = 1000012
kafka_1    |    metric.reporters = []
kafka_1    |    metrics.num.samples = 2
kafka_1    |    metrics.recording.level = INFO
kafka_1    |    metrics.sample.window.ms = 30000
kafka_1    |    min.insync.replicas = 1
kafka_1    |    num.io.threads = 8
kafka_1    |    num.network.threads = 3
kafka_1    |    num.partitions = 1
kafka_1    |    num.recovery.threads.per.data.dir = 1
kafka_1    |    num.replica.fetchers = 1
kafka_1    |    offset.metadata.max.bytes = 4096
kafka_1    |    offsets.commit.required.acks = -1
kafka_1    |    offsets.commit.timeout.ms = 5000
kafka_1    |    offsets.load.buffer.size = 5242880
kafka_1    |    offsets.retention.check.interval.ms = 600000
kafka_1    |    offsets.retention.minutes = 1440
kafka_1    |    offsets.topic.compression.codec = 0
kafka_1    |    offsets.topic.num.partitions = 50
kafka_1    |    offsets.topic.replication.factor = 3
kafka_1    |    offsets.topic.segment.bytes = 104857600
kafka_1    |    port = 9092
kafka_1    |    principal.builder.class = class org.apache.kafka.common.security.auth.DefaultPrincipalBuilder
kafka_1    |    producer.purgatory.purge.interval.requests = 1000
kafka_1    |    queued.max.requests = 500
kafka_1    |    quota.consumer.default = 9223372036854775807
kafka_1    |    quota.producer.default = 9223372036854775807
kafka_1    |    quota.window.num = 11
kafka_1    |    quota.window.size.seconds = 1
kafka_1    |    replica.fetch.backoff.ms = 1000
kafka_1    |    replica.fetch.max.bytes = 1048576
kafka_1    |    replica.fetch.min.bytes = 1
kafka_1    |    replica.fetch.response.max.bytes = 10485760
kafka_1    |    replica.fetch.wait.max.ms = 500
kafka_1    |    replica.high.watermark.checkpoint.interval.ms = 5000
kafka_1    |    replica.lag.time.max.ms = 10000
kafka_1    |    replica.socket.receive.buffer.bytes = 65536
kafka_1    |    replica.socket.timeout.ms = 30000
zk_1       | 2019-07-01 12:38:56,725 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.21.0.3:46170
zk_1       | 2019-07-01 12:38:56,727 [myid:] - INFO  [SyncThread:0:FileTxnLog@216] - Creating new log file: log.296
kafka_1    |    replication.quota.window.num = 11
kafka_1    |    replication.quota.window.size.seconds = 1
kafka_1    |    request.timeout.ms = 30000
kafka_1    |    reserved.broker.max.id = 1000
kafka_1    |    sasl.enabled.mechanisms = [GSSAPI]
kafka_1    |    sasl.kerberos.kinit.cmd = /usr/bin/kinit
kafka_1    |    sasl.kerberos.min.time.before.relogin = 60000
kafka_1    |    sasl.kerberos.principal.to.local.rules = [DEFAULT]
kafka_1    |    sasl.kerberos.service.name = null
kafka_1    |    sasl.kerberos.ticket.renew.jitter = 0.05
kafka_1    |    sasl.kerberos.ticket.renew.window.factor = 0.8
kafka_1    |    sasl.mechanism.inter.broker.protocol = GSSAPI
kafka_1    |    security.inter.broker.protocol = PLAINTEXT
kafka_1    |    socket.receive.buffer.bytes = 102400
kafka_1    |    socket.request.max.bytes = 104857600
kafka_1    |    socket.send.buffer.bytes = 102400
kafka_1    |    ssl.cipher.suites = null
kafka_1    |    ssl.client.auth = none
kafka_1    |    ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
kafka_1    |    ssl.endpoint.identification.algorithm = null
kafka_1    |    ssl.key.password = null
kafka_1    |    ssl.keymanager.algorithm = SunX509
kafka_1    |    ssl.keystore.location = null
kafka_1    |    ssl.keystore.password = null
kafka_1    |    ssl.keystore.type = JKS
kafka_1    |    ssl.protocol = TLS
kafka_1    |    ssl.provider = null
kafka_1    |    ssl.secure.random.implementation = null
kafka_1    |    ssl.trustmanager.algorithm = PKIX
kafka_1    |    ssl.truststore.location = null
kafka_1    |    ssl.truststore.password = null
kafka_1    |    ssl.truststore.type = JKS
kafka_1    |    unclean.leader.election.enable = true
kafka_1    |    zookeeper.connect = zk:2181/broker-0
kafka_1    |    zookeeper.connection.timeout.ms = 10000
kafka_1    |    zookeeper.session.timeout.ms = 10000
kafka_1    |    zookeeper.set.acl = false
kafka_1    |    zookeeper.sync.time.ms = 2000
kafka_1    |  (kafka.server.KafkaConfig)
zk_1       | 2019-07-01 12:38:56,869 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x100011c7a750000 with negotiated timeout 10000 for client /172.21.0.3:46170
zk_1       | 2019-07-01 12:38:56,891 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@487] - Processed session termination for sessionid: 0x100011c7a750000
zk_1       | 2019-07-01 12:38:56,932 [myid:] - WARN  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@376] - Unable to read additional data from client sessionid 0x100011c7a750000, likely client has closed socket
zk_1       | 2019-07-01 12:38:56,934 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxn@1056] - Closed socket connection for client /172.21.0.3:46170 which had sessionid 0x100011c7a750000
zk_1       | 2019-07-01 12:38:56,944 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:NIOServerCnxnFactory@222] - Accepted socket connection from /172.21.0.3:46172
zk_1       | 2019-07-01 12:38:56,945 [myid:] - INFO  [NIOServerCxn.Factory:0.0.0.0/0.0.0.0:2181:ZooKeeperServer@949] - Client attempting to establish new session at /172.21.0.3:46172
zk_1       | 2019-07-01 12:38:57,030 [myid:] - INFO  [SyncThread:0:ZooKeeperServer@694] - Established session 0x100011c7a750001 with negotiated timeout 10000 for client /172.21.0.3:46172
kafka_1    | [2019-07-01 12:38:56,650] INFO starting (kafka.server.KafkaServer)
kafka_1    | [2019-07-01 12:38:56,653] INFO Connecting to zookeeper on zk:2181/broker-0 (kafka.server.KafkaServer)
kafka_1    | [2019-07-01 12:38:56,672] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
kafka_1    | [2019-07-01 12:38:56,676] INFO Client environment:zookeeper.version=3.4.9-1757313, built on 08/23/2016 06:50 GMT (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,676] INFO Client environment:host.name=d8bc390657d9 (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,676] INFO Client environment:java.version=1.8.0_60 (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,676] INFO Client environment:java.vendor=Oracle Corporation (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,677] INFO Client environment:java.home=/usr/lib/jvm/java-8-oracle/jre (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,677] INFO Client environment:java.class.path=:/kafka/bin/../libs/aopalliance-repackaged-2.5.0-b05.jar:/kafka/bin/../libs/argparse4j-0.7.0.jar:/kafka/bin/../libs/connect-api-0.10.2.1.jar:/kafka/bin/../libs/connect-file-0.10.2.1.jar:/kafka/bin/../libs/connect-json-0.10.2.1.jar:/kafka/bin/../libs/connect-runtime-0.10.2.1.jar:/kafka/bin/../libs/connect-transforms-0.10.2.1.jar:/kafka/bin/../libs/guava-18.0.jar:/kafka/bin/../libs/hk2-api-2.5.0-b05.jar:/kafka/bin/../libs/hk2-locator-2.5.0-b05.jar:/kafka/bin/../libs/hk2-utils-2.5.0-b05.jar:/kafka/bin/../libs/jackson-annotations-2.8.0.jar:/kafka/bin/../libs/jackson-annotations-2.8.5.jar:/kafka/bin/../libs/jackson-core-2.8.5.jar:/kafka/bin/../libs/jackson-databind-2.8.5.jar:/kafka/bin/../libs/jackson-jaxrs-base-2.8.5.jar:/kafka/bin/../libs/jackson-jaxrs-json-provider-2.8.5.jar:/kafka/bin/../libs/jackson-module-jaxb-annotations-2.8.5.jar:/kafka/bin/../libs/javassist-3.20.0-GA.jar:/kafka/bin/../libs/javax.annotation-api-1.2.jar:/kafka/bin/../libs/javax.inject-1.jar:/kafka/bin/../libs/javax.inject-2.5.0-b05.jar:/kafka/bin/../libs/javax.servlet-api-3.1.0.jar:/kafka/bin/../libs/javax.ws.rs-api-2.0.1.jar:/kafka/bin/../libs/jersey-client-2.24.jar:/kafka/bin/../libs/jersey-common-2.24.jar:/kafka/bin/../libs/jersey-container-servlet-2.24.jar:/kafka/bin/../libs/jersey-container-servlet-core-2.24.jar:/kafka/bin/../libs/jersey-guava-2.24.jar:/kafka/bin/../libs/jersey-media-jaxb-2.24.jar:/kafka/bin/../libs/jersey-server-2.24.jar:/kafka/bin/../libs/jetty-continuation-9.2.15.v20160210.jar:/kafka/bin/../libs/jetty-http-9.2.15.v20160210.jar:/kafka/bin/../libs/jetty-io-9.2.15.v20160210.jar:/kafka/bin/../libs/jetty-security-9.2.15.v20160210.jar:/kafka/bin/../libs/jetty-server-9.2.15.v20160210.jar:/kafka/bin/../libs/jetty-servlet-9.2.15.v20160210.jar:/kafka/bin/../libs/jetty-servlets-9.2.15.v20160210.jar:/kafka/bin/../libs/jetty-util-9.2.15.v20160210.jar:/kafka/bin/../libs/jopt-simple-5.0.3.jar:/kafka/bin/../libs/kafka-clients-0.10.2.1.jar:/kafka/bin/../libs/kafka-log4j-appender-0.10.2.1.jar:/kafka/bin/../libs/kafka-streams-0.10.2.1.jar:/kafka/bin/../libs/kafka-streams-examples-0.10.2.1.jar:/kafka/bin/../libs/kafka-tools-0.10.2.1.jar:/kafka/bin/../libs/kafka_2.12-0.10.2.1-sources.jar:/kafka/bin/../libs/kafka_2.12-0.10.2.1-test-sources.jar:/kafka/bin/../libs/kafka_2.12-0.10.2.1.jar:/kafka/bin/../libs/log4j-1.2.17.jar:/kafka/bin/../libs/lz4-1.3.0.jar:/kafka/bin/../libs/metrics-core-2.2.0.jar:/kafka/bin/../libs/osgi-resource-locator-1.0.1.jar:/kafka/bin/../libs/reflections-0.9.10.jar:/kafka/bin/../libs/rocksdbjni-5.0.1.jar:/kafka/bin/../libs/scala-library-2.12.1.jar:/kafka/bin/../libs/scala-parser-combinators_2.12-1.0.4.jar:/kafka/bin/../libs/slf4j-api-1.7.21.jar:/kafka/bin/../libs/slf4j-log4j12-1.7.21.jar:/kafka/bin/../libs/snappy-java-1.1.2.6.jar:/kafka/bin/../libs/validation-api-1.1.0.Final.jar:/kafka/bin/../libs/zkclient-0.10.jar:/kafka/bin/../libs/zookeeper-3.4.9.jar (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,677] INFO Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,683] INFO Client environment:java.io.tmpdir=/tmp (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,683] INFO Client environment:java.compiler=<NA> (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,683] INFO Client environment:os.name=Linux (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,683] INFO Client environment:os.arch=amd64 (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,683] INFO Client environment:os.version=4.9.125-linuxkit (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,683] INFO Client environment:user.name=kafka (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,683] INFO Client environment:user.home=/kafka (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,684] INFO Client environment:user.dir=/kafka (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,685] INFO Initiating client connection, connectString=zk:2181 sessionTimeout=10000 watcher=org.I0Itec.zkclient.ZkClient@1fe20588 (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,698] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
kafka_1    | [2019-07-01 12:38:56,701] INFO Opening socket connection to server 221_zk_1.221_default/172.21.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
kafka_1    | [2019-07-01 12:38:56,718] INFO Socket connection established to 221_zk_1.221_default/172.21.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
kafka_1    | [2019-07-01 12:38:56,873] INFO Session establishment complete on server 221_zk_1.221_default/172.21.0.2:2181, sessionid = 0x100011c7a750000, negotiated timeout = 10000 (org.apache.zookeeper.ClientCnxn)
kafka_1    | [2019-07-01 12:38:56,876] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
kafka_1    | [2019-07-01 12:38:56,890] INFO Created zookeeper path /broker-0 (kafka.server.KafkaServer)
kafka_1    | [2019-07-01 12:38:56,890] INFO Terminate ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
kafka_1    | [2019-07-01 12:38:56,936] INFO Session: 0x100011c7a750000 closed (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,936] INFO Initiating client connection, connectString=zk:2181/broker-0 sessionTimeout=10000 watcher=org.I0Itec.zkclient.ZkClient@4b5a5ed1 (org.apache.zookeeper.ZooKeeper)
kafka_1    | [2019-07-01 12:38:56,938] INFO EventThread shut down for session: 0x100011c7a750000 (org.apache.zookeeper.ClientCnxn)
kafka_1    | [2019-07-01 12:38:56,938] INFO Starting ZkClient event thread. (org.I0Itec.zkclient.ZkEventThread)
kafka_1    | [2019-07-01 12:38:56,941] INFO Waiting for keeper state SyncConnected (org.I0Itec.zkclient.ZkClient)
kafka_1    | [2019-07-01 12:38:56,941] INFO Opening socket connection to server 221_zk_1.221_default/172.21.0.2:2181. Will not attempt to authenticate using SASL (unknown error) (org.apache.zookeeper.ClientCnxn)
kafka_1    | [2019-07-01 12:38:56,944] INFO Socket connection established to 221_zk_1.221_default/172.21.0.2:2181, initiating session (org.apache.zookeeper.ClientCnxn)
kafka_1    | [2019-07-01 12:38:57,029] INFO Session establishment complete on server 221_zk_1.221_default/172.21.0.2:2181, sessionid = 0x100011c7a750001, negotiated timeout = 10000 (org.apache.zookeeper.ClientCnxn)
kafka_1    | [2019-07-01 12:38:57,029] INFO zookeeper state changed (SyncConnected) (org.I0Itec.zkclient.ZkClient)
kafka_1    | [2019-07-01 12:38:57,175] INFO Cluster ID = BDDF9e57RLu8iD_aMyORAQ (kafka.server.KafkaServer)
kafka_1    | [2019-07-01 12:38:57,216] INFO [ThrottledRequestReaper-Fetch], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
kafka_1    | [2019-07-01 12:38:57,218] INFO [ThrottledRequestReaper-Produce], Starting  (kafka.server.ClientQuotaManager$ThrottledRequestReaper)
kafka_1    | [2019-07-01 12:38:57,293] INFO Loading logs. (kafka.log.LogManager)
kafka_1    | [2019-07-01 12:38:57,335] INFO Completed load of log __consumer_offsets-13 with 1 log segments and log end offset 0 in 23 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,341] INFO Completed load of log connect-offsets-13 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,348] INFO Completed load of log __consumer_offsets-18 with 1 log segments and log end offset 0 in 3 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,353] INFO Completed load of log __consumer_offsets-9 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,356] INFO Completed load of log __consumer_offsets-49 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,360] INFO Completed load of log __consumer_offsets-7 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,373] INFO Completed load of log connect-status-4 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,378] INFO Completed load of log __consumer_offsets-31 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,388] INFO Completed load of log connect-offsets-5 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,401] INFO Completed load of log __consumer_offsets-32 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,414] INFO Completed load of log __consumer_offsets-42 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,419] INFO Completed load of log connect-offsets-19 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,425] INFO Completed load of log __consumer_offsets-40 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,434] INFO Completed load of log connect-offsets-9 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,442] INFO Completed load of log __consumer_offsets-34 with 1 log segments and log end offset 0 in 3 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,446] INFO Completed load of log connect-offsets-11 with 1 log segments and log end offset 0 in 3 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,448] INFO Completed load of log __consumer_offsets-14 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,455] INFO Completed load of log connect-status-2 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,462] INFO Completed load of log __consumer_offsets-24 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,464] INFO Completed load of log __consumer_offsets-21 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,470] INFO Completed load of log connect-offsets-15 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,479] INFO Completed load of log connect-status-1 with 1 log segments and log end offset 6 in 5 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,488] INFO Completed load of log __consumer_offsets-26 with 1 log segments and log end offset 0 in 3 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,498] INFO Completed load of log __consumer_offsets-27 with 1 log segments and log end offset 0 in 2 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,505] INFO Completed load of log __consumer_offsets-11 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,524] INFO Completed load of log __consumer_offsets-20 with 1 log segments and log end offset 0 in 12 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,527] INFO Completed load of log __consumer_offsets-41 with 1 log segments and log end offset 11 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,530] INFO Completed load of log connect-offsets-23 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,532] INFO Completed load of log __consumer_offsets-12 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,534] INFO Completed load of log __consumer_offsets-10 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,536] INFO Completed load of log __consumer_offsets-2 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,538] INFO Completed load of log connect-offsets-3 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,540] INFO Completed load of log connect-offsets-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,543] INFO Completed load of log __consumer_offsets-38 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,550] INFO Completed load of log __consumer_offsets-6 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,557] INFO Completed load of log __consumer_offsets-1 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,578] INFO Completed load of log connect-offsets-16 with 1 log segments and log end offset 0 in 7 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,586] INFO Completed load of log __consumer_offsets-8 with 1 log segments and log end offset 0 in 5 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,596] INFO Completed load of log connect-offsets-21 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,605] INFO Completed load of log connect-configs-0 with 1 log segments and log end offset 1 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,611] INFO Completed load of log __consumer_offsets-29 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,629] INFO Completed load of log connect-offsets-6 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,632] INFO Completed load of log connect-offsets-1 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,634] INFO Completed load of log connect-offsets-4 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,635] INFO Completed load of log __consumer_offsets-19 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,637] INFO Completed load of log __consumer_offsets-5 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,638] INFO Completed load of log __consumer_offsets-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,642] INFO Completed load of log connect-status-3 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,644] INFO Completed load of log connect-offsets-18 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,646] INFO Completed load of log __consumer_offsets-17 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,648] INFO Completed load of log __consumer_offsets-44 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,649] INFO Completed load of log __consumer_offsets-15 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,650] INFO Completed load of log __consumer_offsets-4 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,652] INFO Completed load of log connect-offsets-12 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,653] INFO Completed load of log __consumer_offsets-16 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,660] INFO Completed load of log __consumer_offsets-25 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,663] INFO Completed load of log __consumer_offsets-47 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,665] INFO Completed load of log __consumer_offsets-46 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,667] INFO Completed load of log __consumer_offsets-48 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,668] INFO Completed load of log __consumer_offsets-36 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,670] INFO Completed load of log __consumer_offsets-28 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,671] INFO Completed load of log connect-offsets-20 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,672] INFO Completed load of log __consumer_offsets-30 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,675] INFO Completed load of log connect-offsets-10 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,677] INFO Completed load of log connect-status-0 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,679] INFO Completed load of log connect-offsets-8 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,680] INFO Completed load of log __consumer_offsets-43 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,682] INFO Completed load of log connect-offsets-17 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,683] INFO Completed load of log __consumer_offsets-22 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,685] INFO Completed load of log __consumer_offsets-35 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,689] INFO Completed load of log connect-offsets-7 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,691] INFO Completed load of log connect-offsets-24 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,692] INFO Completed load of log connect-offsets-22 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,693] INFO Completed load of log connect-offsets-14 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,695] INFO Completed load of log __consumer_offsets-39 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,696] INFO Completed load of log connect-offsets-2 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,698] INFO Completed load of log __consumer_offsets-45 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,699] INFO Completed load of log __consumer_offsets-37 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,701] INFO Completed load of log __consumer_offsets-33 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,703] INFO Completed load of log __consumer_offsets-23 with 1 log segments and log end offset 0 in 0 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,704] INFO Completed load of log __consumer_offsets-3 with 1 log segments and log end offset 0 in 1 ms (kafka.log.Log)
kafka_1    | [2019-07-01 12:38:57,707] INFO Logs loading complete in 414 ms. (kafka.log.LogManager)
kafka_1    | [2019-07-01 12:38:57,788] INFO Starting log cleanup with a period of 300000 ms. (kafka.log.LogManager)
kafka_1    | [2019-07-01 12:38:57,800] INFO Starting log flusher with a default period of 9223372036854775807 ms. (kafka.log.LogManager)
kafka_1    | [2019-07-01 12:38:57,901] INFO Awaiting socket connections on 0.0.0.0:9092. (kafka.network.Acceptor)
kafka_1    | [2019-07-01 12:38:57,906] INFO [Socket Server on Broker 0], Started 1 acceptor threads (kafka.network.SocketServer)
kafka_1    | [2019-07-01 12:38:57,935] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1    | [2019-07-01 12:38:57,937] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1    | [2019-07-01 12:38:57,978] INFO Creating /controller (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
kafka_1    | [2019-07-01 12:38:58,125] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
kafka_1    | [2019-07-01 12:38:58,127] INFO 0 successfully elected as leader (kafka.server.ZookeeperLeaderElector)
connect_1  | [2019-07-01 12:38:59,970] INFO WorkerInfo values:
connect_1  |    jvm.args = -Xms256M, -Xmx2G, -XX:+UseG1GC, -XX:MaxGCPauseMillis=20, -XX:InitiatingHeapOccupancyPercent=35, -XX:+ExplicitGCInvokesConcurrent, -Djava.awt.headless=true, -Dcom.sun.management.jmxremote, -Djava.rmi.server.hostname=, -Dcom.sun.management.jmxremote.rmi.port=9999, -Dcom.sun.management.jmxremote.local.only=false, -Dcom.sun.management.jmxremote.authenticate=false, -Dcom.sun.management.jmxremote.ssl=false, -Dcom.sun.management.jmxremote.port=9999, -Dkafka.logs.dir=/opt/kafka_2.12-2.2.0/bin/../logs, -Dlog4j.configuration=file:/opt/kafka_2.12-2.2.0/bin/../config/connect-log4j.properties
connect_1  |    jvm.spec = Oracle Corporation, Java HotSpot(TM) 64-Bit Server VM, 1.8.0_92, 25.92-b14
connect_1  |    jvm.classpath = /opt/kafka_2.12-2.2.0/connectors/*:/opt/kafka_2.12-2.2.0/bin/../libs/activation-1.1.1.jar:/opt/kafka_2.12-2.2.0/bin/../libs/aopalliance-repackaged-2.5.0-b42.jar:/opt/kafka_2.12-2.2.0/bin/../libs/argparse4j-0.7.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/audience-annotations-0.5.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/commons-lang3-3.8.1.jar:/opt/kafka_2.12-2.2.0/bin/../libs/connect-api-2.2.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/connect-basic-auth-extension-2.2.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/connect-file-2.2.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/connect-json-2.2.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/connect-runtime-2.2.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/connect-transforms-2.2.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/guava-20.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/hk2-api-2.5.0-b42.jar:/opt/kafka_2.12-2.2.0/bin/../libs/hk2-locator-2.5.0-b42.jar:/opt/kafka_2.12-2.2.0/bin/../libs/hk2-utils-2.5.0-b42.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jackson-annotations-2.9.8.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jackson-core-2.9.8.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jackson-databind-2.9.8.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jackson-datatype-jdk8-2.9.8.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-base-2.9.8.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jackson-jaxrs-json-provider-2.9.8.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jackson-module-jaxb-annotations-2.9.8.jar:/opt/kafka_2.12-2.2.0/bin/../libs/javassist-3.22.0-CR2.jar:/opt/kafka_2.12-2.2.0/bin/../libs/javax.annotation-api-1.2.jar:/opt/kafka_2.12-2.2.0/bin/../libs/javax.inject-1.jar:/opt/kafka_2.12-2.2.0/bin/../libs/javax.inject-2.5.0-b42.jar:/opt/kafka_2.12-2.2.0/bin/../libs/javax.servlet-api-3.1.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.1.jar:/opt/kafka_2.12-2.2.0/bin/../libs/javax.ws.rs-api-2.1.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jaxb-api-2.3.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jersey-client-2.27.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jersey-common-2.27.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-2.27.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jersey-container-servlet-core-2.27.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jersey-hk2-2.27.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jersey-media-jaxb-2.27.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jersey-server-2.27.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jetty-client-9.4.14.v20181114.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jetty-continuation-9.4.14.v20181114.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jetty-http-9.4.14.v20181114.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jetty-io-9.4.14.v20181114.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jetty-security-9.4.14.v20181114.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jetty-server-9.4.14.v20181114.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jetty-servlet-9.4.14.v20181114.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jetty-servlets-9.4.14.v20181114.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jetty-util-9.4.14.v20181114.jar:/opt/kafka_2.12-2.2.0/bin/../libs/jopt-simple-5.0.4.jar:/opt/kafka_2.12-2.2.0/bin/../libs/kafka-clients-2.2.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/kafka-log4j-appender-2.2.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/kafka-streams-2.2.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/kafka-streams-examples-2.2.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/kafka-streams-scala_2.12-2.2.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/kafka-streams-test-utils-2.2.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/kafka-tools-2.2.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0-sources.jar:/opt/kafka_2.12-2.2.0/bin/../libs/kafka_2.12-2.2.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/log4j-1.2.17.jar:/opt/kafka_2.12-2.2.0/bin/../libs/lz4-java-1.5.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/maven-artifact-3.6.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/metrics-core-2.2.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/osgi-resource-locator-1.0.1.jar:/opt/kafka_2.12-2.2.0/bin/../libs/plexus-utils-3.1.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/reflections-0.9.11.jar:/opt/kafka_2.12-2.2.0/bin/../libs/rocksdbjni-5.15.10.jar:/opt/kafka_2.12-2.2.0/bin/../libs/scala-library-2.12.8.jar:/opt/kafka_2.12-2.2.0/bin/../libs/scala-logging_2.12-3.9.0.jar:/opt/kafka_2.12-2.2.0/bin/../libs/scala-reflect-2.12.8.jar:/opt/kafka_2.12-2.2.0/bin/../libs/slf4j-api-1.7.25.jar:/opt/kafka_2.12-2.2.0/bin/../libs/slf4j-log4j12-1.7.25.jar:/opt/kafka_2.12-2.2.0/bin/../libs/snappy-java-1.1.7.2.jar:/opt/kafka_2.12-2.2.0/bin/../libs/validation-api-1.1.0.Final.jar:/opt/kafka_2.12-2.2.0/bin/../libs/zkclient-0.11.jar:/opt/kafka_2.12-2.2.0/bin/../libs/zookeeper-3.4.13.jar:/opt/kafka_2.12-2.2.0/bin/../libs/zstd-jni-1.3.8-1.jar
connect_1  |    os.spec = Linux, amd64, 4.9.125-linuxkit
connect_1  |    os.vcpus = 2
connect_1  |  (org.apache.kafka.connect.runtime.WorkerInfo:71)
connect_1  | [2019-07-01 12:39:00,043] INFO Scanning for plugin classes. This might take a moment ... (org.apache.kafka.connect.cli.ConnectDistributed:89)
zk_1       | 2019-07-01 12:39:00,247 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100011c7a750001 type:delete cxid:0x122 zxid:0x29b txntype:-1 reqpath:n/a Error Path:/broker-0/admin/preferred_replica_election Error:KeeperErrorCode = NoNode for /broker-0/admin/preferred_replica_election
connect_1  | [2019-07-01 12:39:00,262] INFO Loading plugin from: /usr/local/share/kafka/plugins/kafka-connect-jdbc (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:215)
kafka_1    | [2019-07-01 12:39:00,282] INFO New leader is 0 (kafka.server.ZookeeperLeaderElector$LeaderChangeListener)
kafka_1    | [2019-07-01 12:39:00,321] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1    | [2019-07-01 12:39:00,339] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1    | [2019-07-01 12:39:00,346] INFO [ExpirationReaper-0], Starting  (kafka.server.DelayedOperationPurgatory$ExpiredOperationReaper)
kafka_1    | [2019-07-01 12:39:00,402] INFO [GroupCoordinator 0]: Starting up. (kafka.coordinator.GroupCoordinator)
kafka_1    | [2019-07-01 12:39:00,412] INFO [GroupCoordinator 0]: Startup complete. (kafka.coordinator.GroupCoordinator)
kafka_1    | [2019-07-01 12:39:00,429] INFO [Group Metadata Manager on Broker 0]: Removed 0 expired offsets in 16 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:00,518] INFO Will not load MX4J, mx4j-tools.jar is not in the classpath (kafka.utils.Mx4jLoader$)
kafka_1    | [2019-07-01 12:39:00,662] INFO Creating /brokers/ids/0 (is it secure? false) (kafka.utils.ZKCheckedEphemeral)
zk_1       | 2019-07-01 12:39:00,666 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100011c7a750001 type:create cxid:0x131 zxid:0x29c txntype:-1 reqpath:n/a Error Path:/broker-0/brokers Error:KeeperErrorCode = NodeExists for /broker-0/brokers
zk_1       | 2019-07-01 12:39:00,668 [myid:] - INFO  [ProcessThread(sid:0 cport:2181)::PrepRequestProcessor@653] - Got user-level KeeperException when processing sessionid:0x100011c7a750001 type:create cxid:0x132 zxid:0x29d txntype:-1 reqpath:n/a Error Path:/broker-0/brokers/ids Error:KeeperErrorCode = NodeExists for /broker-0/brokers/ids
kafka_1    | [2019-07-01 12:39:00,756] INFO Result of znode creation is: OK (kafka.utils.ZKCheckedEphemeral)
kafka_1    | [2019-07-01 12:39:00,774] INFO Registered broker 0 at path /brokers/ids/0 with addresses: EndPoint(kafka,9092,ListenerName(PLAINTEXT),PLAINTEXT) (kafka.utils.ZkUtils)
kafka_1    | [2019-07-01 12:39:00,799] INFO Kafka version : 0.10.2.1 (org.apache.kafka.common.utils.AppInfoParser)
kafka_1    | [2019-07-01 12:39:00,805] INFO Kafka commitId : e89bffd6b2eff799 (org.apache.kafka.common.utils.AppInfoParser)
kafka_1    | [2019-07-01 12:39:00,810] INFO [Kafka Server 0], started (kafka.server.KafkaServer)
kafka_1    | [2019-07-01 12:39:01,570] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,connect-offsets-20,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,connect-offsets-7,connect-offsets-24,connect-offsets-16,__consumer_offsets-25,connect-status-4,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,connect-offsets-3,connect-offsets-21,connect-offsets-11,__consumer_offsets-47,connect-offsets-6,__consumer_offsets-16,connect-configs-0,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,connect-status-3,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,connect-offsets-17,__consumer_offsets-37,connect-offsets-10,__consumer_offsets-15,__consumer_offsets-24,connect-offsets-2,connect-offsets-18,connect-offsets-23,connect-status-2,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,connect-offsets-15,__consumer_offsets-13,__consumer_offsets-2,connect-offsets-4,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,connect-offsets-12,connect-offsets-5,connect-offsets-13,connect-offsets-14,connect-offsets-0,connect-status-0,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,connect-offsets-8,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,connect-offsets-9,__consumer_offsets-29,connect-status-1,connect-offsets-1,connect-offsets-19,connect-offsets-22,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 (kafka.server.ReplicaFetcherManager)
connect_1  | [WARN ] 2019-07-01 12:39:03.187 [main] Version - Error while loading version:
connect_1  | java.lang.NullPointerException: null
connect_1  |    at java.util.Properties$LineReader.readLine(Properties.java:434) ~[?:1.8.0_92]
connect_1  |    at java.util.Properties.load0(Properties.java:353) ~[?:1.8.0_92]
connect_1  |    at java.util.Properties.load(Properties.java:341) ~[?:1.8.0_92]
connect_1  |    at com.it.ibm.kafka.utilities.Version.<clinit>(Version.java:18) [kafka-connector-1.0.0.0.jar:1.0.0.0]
connect_1  |    at com.it.ibm.kafka.connectors.JdbcSinkConnector.version(JdbcSinkConnector.java:30) [kafka-connector-1.0.0.0.jar:1.0.0.0]
connect_1  |    at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.versionFor(DelegatingClassLoader.java:340) [connect-runtime-2.2.0.jar:?]
connect_1  |    at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.versionFor(DelegatingClassLoader.java:345) [connect-runtime-2.2.0.jar:?]
connect_1  |    at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.getPluginDesc(DelegatingClassLoader.java:321) [connect-runtime-2.2.0.jar:?]
connect_1  |    at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanPluginPath(DelegatingClassLoader.java:302) [connect-runtime-2.2.0.jar:?]
connect_1  |    at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.scanUrlsAndAddPlugins(DelegatingClassLoader.java:237) [connect-runtime-2.2.0.jar:?]
connect_1  |    at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.registerPlugin(DelegatingClassLoader.java:229) [connect-runtime-2.2.0.jar:?]
connect_1  |    at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initPluginLoader(DelegatingClassLoader.java:198) [connect-runtime-2.2.0.jar:?]
connect_1  |    at org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader.initLoaders(DelegatingClassLoader.java:175) [connect-runtime-2.2.0.jar:?]
connect_1  |    at org.apache.kafka.connect.runtime.isolation.Plugins.<init>(Plugins.java:61) [connect-runtime-2.2.0.jar:?]
connect_1  |    at org.apache.kafka.connect.cli.ConnectDistributed.startConnect(ConnectDistributed.java:90) [connect-runtime-2.2.0.jar:?]
connect_1  |    at org.apache.kafka.connect.cli.ConnectDistributed.main(ConnectDistributed.java:77) [connect-runtime-2.2.0.jar:?]
connect_1  | [DEBUG] 2019-07-01 12:39:03.205 [main] JdbcSinkConnector - version N/A
connect_1  | [DEBUG] 2019-07-01 12:39:03.211 [main] JdbcSourceConnector - version source
connect_1  | [2019-07-01 12:39:03,224] INFO Registered loader: PluginClassLoader{pluginLocation=file:/usr/local/share/kafka/plugins/kafka-connect-jdbc/} (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:238)
connect_1  | [2019-07-01 12:39:03,224] INFO Added plugin 'com.it.ibm.kafka.connectors.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:03,225] INFO Added plugin 'com.it.ibm.kafka.connectors.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:03,225] INFO Added plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:03,225] INFO Added plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:03,225] INFO Added plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:03,225] INFO Added plugin 'org.apache.kafka.common.config.provider.FileConfigProvider' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
kafka_1    | [2019-07-01 12:39:03,349] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-25 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,407] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-25 in 57 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,419] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-31 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,422] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-31 in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,422] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-37 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,448] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-37 in 26 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,448] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-43 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,451] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-43 in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,451] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-49 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,464] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-49 in 13 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,464] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-44 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,486] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-44 in 22 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,486] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-1 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,488] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-1 in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,488] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-7 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,492] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-7 in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,492] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-13 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,517] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-13 in 25 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,517] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-19 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,520] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-19 in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,520] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-2 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,523] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-2 in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,524] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-8 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,534] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-8 in 10 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,534] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-14 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,537] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-14 in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,537] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-20 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,540] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-20 in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,540] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-26 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,564] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-26 in 24 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,565] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-32 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,567] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-32 in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,567] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-38 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,572] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-38 in 5 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,572] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-3 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,594] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-3 in 22 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,595] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-9 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,599] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-9 in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,599] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-15 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,601] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-15 in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,601] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-21 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,614] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-21 in 13 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,614] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-27 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,616] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-27 in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,616] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-33 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,619] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-33 in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,619] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-39 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,622] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-39 in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,622] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-45 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,626] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-45 in 4 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,634] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-22 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,636] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-22 in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,636] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-28 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,639] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-28 in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,639] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-34 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,642] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-34 in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,642] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-40 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,656] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-40 in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,656] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-46 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,658] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-46 in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,659] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-41 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,697] INFO [GroupCoordinator 0]: Loading group metadata for connect-cluster-A with generation 11 (kafka.coordinator.GroupCoordinator)
kafka_1    | [2019-07-01 12:39:03,698] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-41 in 39 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,704] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-47 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,707] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-47 in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,714] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-4 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,717] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-4 in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,717] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-10 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,719] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-10 in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,720] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-16 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,722] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-16 in 2 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,727] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-5 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,731] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-5 in 3 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,731] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-11 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,739] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-11 in 7 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,742] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-17 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,797] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-17 in 54 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,798] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-23 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,799] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-23 in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,799] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-29 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,800] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-29 in 0 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,801] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-35 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,802] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-35 in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,802] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-0 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,803] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-0 in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,814] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-6 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,815] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-6 in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,817] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-12 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,818] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-12 in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,820] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-18 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,821] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-18 in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,824] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-24 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,826] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-24 in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,826] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-30 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,866] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-30 in 40 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,866] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-36 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,868] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-36 in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,868] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-42 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,870] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-42 in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,870] INFO [Group Metadata Manager on Broker 0]: Loading offsets and group metadata from __consumer_offsets-48 (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:03,871] INFO [Group Metadata Manager on Broker 0]: Finished loading offsets from __consumer_offsets-48 in 1 milliseconds. (kafka.coordinator.GroupMetadataManager)
kafka_1    | [2019-07-01 12:39:04,210] INFO [ReplicaFetcherManager on broker 0] Removed fetcher for partitions __consumer_offsets-22,__consumer_offsets-30,connect-offsets-20,__consumer_offsets-8,__consumer_offsets-21,__consumer_offsets-4,__consumer_offsets-27,__consumer_offsets-7,__consumer_offsets-9,__consumer_offsets-46,connect-offsets-7,connect-offsets-24,connect-offsets-16,__consumer_offsets-25,connect-status-4,__consumer_offsets-35,__consumer_offsets-41,__consumer_offsets-33,__consumer_offsets-23,__consumer_offsets-49,connect-offsets-3,connect-offsets-21,connect-offsets-11,__consumer_offsets-47,connect-offsets-6,__consumer_offsets-16,connect-configs-0,__consumer_offsets-28,__consumer_offsets-31,__consumer_offsets-36,connect-status-3,__consumer_offsets-42,__consumer_offsets-3,__consumer_offsets-18,connect-offsets-17,__consumer_offsets-37,connect-offsets-10,__consumer_offsets-15,__consumer_offsets-24,connect-offsets-2,connect-offsets-18,connect-offsets-23,connect-status-2,__consumer_offsets-38,__consumer_offsets-17,__consumer_offsets-48,__consumer_offsets-19,__consumer_offsets-11,connect-offsets-15,__consumer_offsets-13,__consumer_offsets-2,connect-offsets-4,__consumer_offsets-43,__consumer_offsets-6,__consumer_offsets-14,connect-offsets-12,connect-offsets-5,connect-offsets-13,connect-offsets-14,connect-offsets-0,connect-status-0,__consumer_offsets-20,__consumer_offsets-0,__consumer_offsets-44,connect-offsets-8,__consumer_offsets-39,__consumer_offsets-12,__consumer_offsets-45,__consumer_offsets-1,__consumer_offsets-5,__consumer_offsets-26,connect-offsets-9,__consumer_offsets-29,connect-status-1,connect-offsets-1,connect-offsets-19,connect-offsets-22,__consumer_offsets-34,__consumer_offsets-10,__consumer_offsets-32,__consumer_offsets-40 (kafka.server.ReplicaFetcherManager)
connect_1  | [2019-07-01 12:39:05,996] INFO Registered loader: sun.misc.Launcher$AppClassLoader@764c12b6 (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:238)
connect_1  | [2019-07-01 12:39:05,996] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:05,996] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:05,997] INFO Added plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:05,997] INFO Added plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:05,998] INFO Added plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,002] INFO Added plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,003] INFO Added plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,003] INFO Added plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,004] INFO Added plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,004] INFO Added plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,004] INFO Added plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,004] INFO Added plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,004] INFO Added plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,005] INFO Added plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,005] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,005] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,005] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,006] INFO Added plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,006] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,006] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,006] INFO Added plugin 'org.apache.kafka.connect.transforms.ReplaceField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,006] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,007] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,007] INFO Added plugin 'org.apache.kafka.connect.transforms.SetSchemaMetadata$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,008] INFO Added plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,008] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,008] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,008] INFO Added plugin 'org.apache.kafka.connect.transforms.HoistField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,009] INFO Added plugin 'org.apache.kafka.connect.transforms.Cast$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,009] INFO Added plugin 'org.apache.kafka.connect.transforms.ExtractField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,009] INFO Added plugin 'org.apache.kafka.connect.transforms.MaskField$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,009] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,009] INFO Added plugin 'org.apache.kafka.connect.transforms.InsertField$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,010] INFO Added plugin 'org.apache.kafka.connect.transforms.TimestampConverter$Key' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,010] INFO Added plugin 'org.apache.kafka.connect.transforms.Flatten$Value' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,010] INFO Added plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:167)
connect_1  | [2019-07-01 12:39:06,012] INFO Added aliases 'JdbcSinkConnector' and 'JdbcSink' to plugin 'com.it.ibm.kafka.connectors.JdbcSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,013] INFO Added aliases 'JdbcSourceConnector' and 'JdbcSource' to plugin 'com.it.ibm.kafka.connectors.JdbcSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,013] INFO Added aliases 'FileStreamSinkConnector' and 'FileStreamSink' to plugin 'org.apache.kafka.connect.file.FileStreamSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,014] INFO Added aliases 'FileStreamSourceConnector' and 'FileStreamSource' to plugin 'org.apache.kafka.connect.file.FileStreamSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,016] INFO Added aliases 'MockConnector' and 'Mock' to plugin 'org.apache.kafka.connect.tools.MockConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,017] INFO Added aliases 'MockSinkConnector' and 'MockSink' to plugin 'org.apache.kafka.connect.tools.MockSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,017] INFO Added aliases 'MockSourceConnector' and 'MockSource' to plugin 'org.apache.kafka.connect.tools.MockSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,017] INFO Added aliases 'SchemaSourceConnector' and 'SchemaSource' to plugin 'org.apache.kafka.connect.tools.SchemaSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,018] INFO Added aliases 'VerifiableSinkConnector' and 'VerifiableSink' to plugin 'org.apache.kafka.connect.tools.VerifiableSinkConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,018] INFO Added aliases 'VerifiableSourceConnector' and 'VerifiableSource' to plugin 'org.apache.kafka.connect.tools.VerifiableSourceConnector' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,018] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,018] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,019] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,019] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,020] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,020] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,020] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,020] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,021] INFO Added aliases 'ByteArrayConverter' and 'ByteArray' to plugin 'org.apache.kafka.connect.converters.ByteArrayConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,021] INFO Added aliases 'DoubleConverter' and 'Double' to plugin 'org.apache.kafka.connect.converters.DoubleConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,021] INFO Added aliases 'FloatConverter' and 'Float' to plugin 'org.apache.kafka.connect.converters.FloatConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,021] INFO Added aliases 'IntegerConverter' and 'Integer' to plugin 'org.apache.kafka.connect.converters.IntegerConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,022] INFO Added aliases 'LongConverter' and 'Long' to plugin 'org.apache.kafka.connect.converters.LongConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,022] INFO Added aliases 'ShortConverter' and 'Short' to plugin 'org.apache.kafka.connect.converters.ShortConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,023] INFO Added aliases 'JsonConverter' and 'Json' to plugin 'org.apache.kafka.connect.json.JsonConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,023] INFO Added alias 'SimpleHeaderConverter' to plugin 'org.apache.kafka.connect.storage.SimpleHeaderConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:383)
connect_1  | [2019-07-01 12:39:06,024] INFO Added aliases 'StringConverter' and 'String' to plugin 'org.apache.kafka.connect.storage.StringConverter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:386)
connect_1  | [2019-07-01 12:39:06,025] INFO Added alias 'RegexRouter' to plugin 'org.apache.kafka.connect.transforms.RegexRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:383)
connect_1  | [2019-07-01 12:39:06,026] INFO Added alias 'TimestampRouter' to plugin 'org.apache.kafka.connect.transforms.TimestampRouter' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:383)
connect_1  | [2019-07-01 12:39:06,026] INFO Added alias 'ValueToKey' to plugin 'org.apache.kafka.connect.transforms.ValueToKey' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:383)
connect_1  | [2019-07-01 12:39:06,027] INFO Added alias 'BasicAuthSecurityRestExtension' to plugin 'org.apache.kafka.connect.rest.basic.auth.extension.BasicAuthSecurityRestExtension' (org.apache.kafka.connect.runtime.isolation.DelegatingClassLoader:383)
connect_1  | [2019-07-01 12:39:06,046] INFO DistributedConfig values:
connect_1  |    access.control.allow.methods =
connect_1  |    access.control.allow.origin =
connect_1  |    bootstrap.servers = [kafka:9092]
connect_1  |    client.dns.lookup = default
connect_1  |    client.id =
connect_1  |    config.providers = []
connect_1  |    config.storage.replication.factor = 1
connect_1  |    config.storage.topic = connect-configs
connect_1  |    connections.max.idle.ms = 540000
connect_1  |    group.id = connect-cluster-A
connect_1  |    header.converter = class org.apache.kafka.connect.storage.SimpleHeaderConverter
connect_1  |    heartbeat.interval.ms = 3000
connect_1  |    internal.key.converter = class org.apache.kafka.connect.json.JsonConverter
connect_1  |    internal.value.converter = class org.apache.kafka.connect.json.JsonConverter
connect_1  |    key.converter = class org.apache.kafka.connect.json.JsonConverter
connect_1  |    listeners = null
connect_1  |    metadata.max.age.ms = 300000
connect_1  |    metric.reporters = []
connect_1  |    metrics.num.samples = 2
connect_1  |    metrics.recording.level = INFO
connect_1  |    metrics.sample.window.ms = 30000
connect_1  |    offset.flush.interval.ms = 10000
connect_1  |    offset.flush.timeout.ms = 5000
connect_1  |    offset.storage.partitions = 25
connect_1  |    offset.storage.replication.factor = 1
connect_1  |    offset.storage.topic = connect-offsets
connect_1  |    plugin.path = [/usr/local/share/kafka/plugins/]
connect_1  |    rebalance.timeout.ms = 60000
connect_1  |    receive.buffer.bytes = 32768
connect_1  |    reconnect.backoff.max.ms = 1000
connect_1  |    reconnect.backoff.ms = 50
connect_1  |    request.timeout.ms = 40000
connect_1  |    rest.advertised.host.name = null
connect_1  |    rest.advertised.listener = null
connect_1  |    rest.advertised.port = null
connect_1  |    rest.extension.classes = []
connect_1  |    rest.host.name = null
connect_1  |    rest.port = 8083
connect_1  |    retry.backoff.ms = 100
connect_1  |    sasl.client.callback.handler.class = null
connect_1  |    sasl.jaas.config = null
connect_1  |    sasl.kerberos.kinit.cmd = /usr/bin/kinit
connect_1  |    sasl.kerberos.min.time.before.relogin = 60000
connect_1  |    sasl.kerberos.service.name = null
connect_1  |    sasl.kerberos.ticket.renew.jitter = 0.05
connect_1  |    sasl.kerberos.ticket.renew.window.factor = 0.8
connect_1  |    sasl.login.callback.handler.class = null
connect_1  |    sasl.login.class = null
connect_1  |    sasl.login.refresh.buffer.seconds = 300
connect_1  |    sasl.login.refresh.min.period.seconds = 60
connect_1  |    sasl.login.refresh.window.factor = 0.8
connect_1  |    sasl.login.refresh.window.jitter = 0.05
connect_1  |    sasl.mechanism = GSSAPI
connect_1  |    security.protocol = PLAINTEXT
connect_1  |    send.buffer.bytes = 131072
connect_1  |    session.timeout.ms = 10000
connect_1  |    ssl.cipher.suites = null
connect_1  |    ssl.client.auth = none
connect_1  |    ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
connect_1  |    ssl.endpoint.identification.algorithm = https
connect_1  |    ssl.key.password = null
connect_1  |    ssl.keymanager.algorithm = SunX509
connect_1  |    ssl.keystore.location = null
connect_1  |    ssl.keystore.password = null
connect_1  |    ssl.keystore.type = JKS
connect_1  |    ssl.protocol = TLS
connect_1  |    ssl.provider = null
connect_1  |    ssl.secure.random.implementation = null
connect_1  |    ssl.trustmanager.algorithm = PKIX
connect_1  |    ssl.truststore.location = null
connect_1  |    ssl.truststore.password = null
connect_1  |    ssl.truststore.type = JKS
connect_1  |    status.storage.partitions = 5
connect_1  |    status.storage.replication.factor = 1
connect_1  |    status.storage.topic = connect-status
connect_1  |    task.shutdown.graceful.timeout.ms = 5000
connect_1  |    value.converter = class org.apache.kafka.connect.json.JsonConverter
connect_1  |    worker.sync.timeout.ms = 3000
connect_1  |    worker.unsync.backoff.ms = 300000
connect_1  |  (org.apache.kafka.connect.runtime.distributed.DistributedConfig:279)
connect_1  | [2019-07-01 12:39:06,048] INFO Worker configuration property 'internal.key.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig:322)
connect_1  | [2019-07-01 12:39:06,048] INFO Worker configuration property 'internal.key.converter.schemas.enable' (along with all configuration for 'internal.key.converter') is deprecated and may be removed in an upcoming release. The specified value 'false' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig:322)
connect_1  | [2019-07-01 12:39:06,049] INFO Worker configuration property 'internal.value.converter' is deprecated and may be removed in an upcoming release. The specified value 'org.apache.kafka.connect.json.JsonConverter' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig:322)
connect_1  | [2019-07-01 12:39:06,049] INFO Worker configuration property 'internal.value.converter.schemas.enable' (along with all configuration for 'internal.value.converter') is deprecated and may be removed in an upcoming release. The specified value 'false' matches the default, so this property can be safely removed from the worker configuration. (org.apache.kafka.connect.runtime.WorkerConfig:322)
connect_1  | [2019-07-01 12:39:06,051] INFO Creating Kafka admin client (org.apache.kafka.connect.util.ConnectUtils:43)
connect_1  | [2019-07-01 12:39:06,061] INFO AdminClientConfig values:
connect_1  |    bootstrap.servers = [kafka:9092]
connect_1  |    client.dns.lookup = default
connect_1  |    client.id =
connect_1  |    connections.max.idle.ms = 300000
connect_1  |    metadata.max.age.ms = 300000
connect_1  |    metric.reporters = []
connect_1  |    metrics.num.samples = 2
connect_1  |    metrics.recording.level = INFO
connect_1  |    metrics.sample.window.ms = 30000
connect_1  |    receive.buffer.bytes = 65536
connect_1  |    reconnect.backoff.max.ms = 1000
connect_1  |    reconnect.backoff.ms = 50
connect_1  |    request.timeout.ms = 120000
connect_1  |    retries = 5
connect_1  |    retry.backoff.ms = 100
connect_1  |    sasl.client.callback.handler.class = null
connect_1  |    sasl.jaas.config = null
connect_1  |    sasl.kerberos.kinit.cmd = /usr/bin/kinit
connect_1  |    sasl.kerberos.min.time.before.relogin = 60000
connect_1  |    sasl.kerberos.service.name = null
connect_1  |    sasl.kerberos.ticket.renew.jitter = 0.05
connect_1  |    sasl.kerberos.ticket.renew.window.factor = 0.8
connect_1  |    sasl.login.callback.handler.class = null
connect_1  |    sasl.login.class = null
connect_1  |    sasl.login.refresh.buffer.seconds = 300
connect_1  |    sasl.login.refresh.min.period.seconds = 60
connect_1  |    sasl.login.refresh.window.factor = 0.8
connect_1  |    sasl.login.refresh.window.jitter = 0.05
connect_1  |    sasl.mechanism = GSSAPI
connect_1  |    security.protocol = PLAINTEXT
connect_1  |    send.buffer.bytes = 131072
connect_1  |    ssl.cipher.suites = null
connect_1  |    ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
connect_1  |    ssl.endpoint.identification.algorithm = https
connect_1  |    ssl.key.password = null
connect_1  |    ssl.keymanager.algorithm = SunX509
connect_1  |    ssl.keystore.location = null
connect_1  |    ssl.keystore.password = null
connect_1  |    ssl.keystore.type = JKS
connect_1  |    ssl.protocol = TLS
connect_1  |    ssl.provider = null
connect_1  |    ssl.secure.random.implementation = null
connect_1  |    ssl.trustmanager.algorithm = PKIX
connect_1  |    ssl.truststore.location = null
connect_1  |    ssl.truststore.password = null
connect_1  |    ssl.truststore.type = JKS
connect_1  |  (org.apache.kafka.clients.admin.AdminClientConfig:279)
connect_1  | [2019-07-01 12:39:06,119] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,120] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,121] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,121] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,122] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,122] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,123] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,123] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,125] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,126] WARN The configuration 'port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,126] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,127] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,128] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,128] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,135] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,135] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,135] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,136] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:06,136] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser:109)
connect_1  | [2019-07-01 12:39:06,137] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser:110)
connect_1  | [2019-07-01 12:39:06,370] INFO Kafka cluster ID: BDDF9e57RLu8iD_aMyORAQ (org.apache.kafka.connect.util.ConnectUtils:59)
connect_1  | [2019-07-01 12:39:06,408] INFO Logging initialized @7733ms to org.eclipse.jetty.util.log.Slf4jLog (org.eclipse.jetty.util.log:193)
connect_1  | [2019-07-01 12:39:06,470] INFO Added connector for http://:8083 (org.apache.kafka.connect.runtime.rest.RestServer:120)
connect_1  | [2019-07-01 12:39:06,471] INFO Starting REST server (org.apache.kafka.connect.runtime.rest.RestServer:164)
connect_1  | [2019-07-01 12:39:06,628] INFO jetty-9.4.14.v20181114; built: 2018-11-14T21:20:31.478Z; git: c4550056e785fb5665914545889f21dc136ad9e6; jvm 1.8.0_92-b14 (org.eclipse.jetty.server.Server:370)
connect_1  | [2019-07-01 12:39:06,698] INFO DefaultSessionIdManager workerName=node0 (org.eclipse.jetty.server.session:365)
connect_1  | [2019-07-01 12:39:06,698] INFO No SessionScavenger set, using defaults (org.eclipse.jetty.server.session:370)
connect_1  | [2019-07-01 12:39:06,701] INFO node0 Scavenging every 660000ms (org.eclipse.jetty.server.session:149)
connect_1  | Jul 01, 2019 12:39:07 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
connect_1  | WARNING: A provider org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource will be ignored.
connect_1  | Jul 01, 2019 12:39:07 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
connect_1  | WARNING: A provider org.apache.kafka.connect.runtime.rest.resources.RootResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider org.apache.kafka.connect.runtime.rest.resources.RootResource will be ignored.
connect_1  | Jul 01, 2019 12:39:07 PM org.glassfish.jersey.internal.inject.Providers checkProviderRuntime
connect_1  | WARNING: A provider org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource registered in SERVER runtime does not implement any provider interfaces applicable in the SERVER runtime. Due to constraint configuration problems the provider org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource will be ignored.
connect_1  | Jul 01, 2019 12:39:07 PM org.glassfish.jersey.internal.Errors logErrors
connect_1  | WARNING: The following warnings have been detected: WARNING: The (sub)resource method createConnector in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
connect_1  | WARNING: The (sub)resource method listConnectors in org.apache.kafka.connect.runtime.rest.resources.ConnectorsResource contains empty path annotation.
connect_1  | WARNING: The (sub)resource method listConnectorPlugins in org.apache.kafka.connect.runtime.rest.resources.ConnectorPluginsResource contains empty path annotation.
connect_1  | WARNING: The (sub)resource method serverInfo in org.apache.kafka.connect.runtime.rest.resources.RootResource contains empty path annotation.
connect_1  |
connect_1  | [2019-07-01 12:39:07,518] INFO Started o.e.j.s.ServletContextHandler@604b1e1d{/,null,AVAILABLE} (org.eclipse.jetty.server.handler.ContextHandler:855)
connect_1  | [2019-07-01 12:39:07,529] INFO Started http_8083@5de06ba5{HTTP/1.1,[http/1.1]}{0.0.0.0:8083} (org.eclipse.jetty.server.AbstractConnector:292)
connect_1  | [2019-07-01 12:39:07,529] INFO Started @8854ms (org.eclipse.jetty.server.Server:407)
connect_1  | [2019-07-01 12:39:07,531] INFO Advertised URI: http://172.21.0.4:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:271)
connect_1  | [2019-07-01 12:39:07,531] INFO REST server listening at http://172.21.0.4:8083/, advertising URL http://172.21.0.4:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:219)
connect_1  | [2019-07-01 12:39:07,532] INFO Advertised URI: http://172.21.0.4:8083/ (org.apache.kafka.connect.runtime.rest.RestServer:271)
connect_1  | [2019-07-01 12:39:07,545] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser:109)
connect_1  | [2019-07-01 12:39:07,545] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser:110)
connect_1  | [2019-07-01 12:39:07,680] INFO JsonConverterConfig values:
connect_1  |    converter.type = key
connect_1  |    schemas.cache.size = 1000
connect_1  |    schemas.enable = false
connect_1  |  (org.apache.kafka.connect.json.JsonConverterConfig:279)
connect_1  | [2019-07-01 12:39:07,681] INFO JsonConverterConfig values:
connect_1  |    converter.type = value
connect_1  |    schemas.cache.size = 1000
connect_1  |    schemas.enable = false
connect_1  |  (org.apache.kafka.connect.json.JsonConverterConfig:279)
connect_1  | [2019-07-01 12:39:07,725] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser:109)
connect_1  | [2019-07-01 12:39:07,725] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser:110)
connect_1  | [2019-07-01 12:39:07,728] INFO Kafka Connect distributed worker initialization took 7685ms (org.apache.kafka.connect.cli.ConnectDistributed:124)
connect_1  | [2019-07-01 12:39:07,728] INFO Kafka Connect starting (org.apache.kafka.connect.runtime.Connect:50)
connect_1  | [2019-07-01 12:39:07,732] INFO Kafka Connect started (org.apache.kafka.connect.runtime.Connect:55)
connect_1  | [2019-07-01 12:39:07,733] INFO Herder starting (org.apache.kafka.connect.runtime.distributed.DistributedHerder:212)
connect_1  | [2019-07-01 12:39:07,734] INFO Worker starting (org.apache.kafka.connect.runtime.Worker:162)
connect_1  | [2019-07-01 12:39:07,734] INFO Starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:108)
connect_1  | [2019-07-01 12:39:07,734] INFO Starting KafkaBasedLog with topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:125)
connect_1  | [2019-07-01 12:39:07,735] INFO AdminClientConfig values:
connect_1  |    bootstrap.servers = [kafka:9092]
connect_1  |    client.dns.lookup = default
connect_1  |    client.id =
connect_1  |    connections.max.idle.ms = 300000
connect_1  |    metadata.max.age.ms = 300000
connect_1  |    metric.reporters = []
connect_1  |    metrics.num.samples = 2
connect_1  |    metrics.recording.level = INFO
connect_1  |    metrics.sample.window.ms = 30000
connect_1  |    receive.buffer.bytes = 65536
connect_1  |    reconnect.backoff.max.ms = 1000
connect_1  |    reconnect.backoff.ms = 50
connect_1  |    request.timeout.ms = 120000
connect_1  |    retries = 5
connect_1  |    retry.backoff.ms = 100
connect_1  |    sasl.client.callback.handler.class = null
connect_1  |    sasl.jaas.config = null
connect_1  |    sasl.kerberos.kinit.cmd = /usr/bin/kinit
connect_1  |    sasl.kerberos.min.time.before.relogin = 60000
connect_1  |    sasl.kerberos.service.name = null
connect_1  |    sasl.kerberos.ticket.renew.jitter = 0.05
connect_1  |    sasl.kerberos.ticket.renew.window.factor = 0.8
connect_1  |    sasl.login.callback.handler.class = null
connect_1  |    sasl.login.class = null
connect_1  |    sasl.login.refresh.buffer.seconds = 300
connect_1  |    sasl.login.refresh.min.period.seconds = 60
connect_1  |    sasl.login.refresh.window.factor = 0.8
connect_1  |    sasl.login.refresh.window.jitter = 0.05
connect_1  |    sasl.mechanism = GSSAPI
connect_1  |    security.protocol = PLAINTEXT
connect_1  |    send.buffer.bytes = 131072
connect_1  |    ssl.cipher.suites = null
connect_1  |    ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
connect_1  |    ssl.endpoint.identification.algorithm = https
connect_1  |    ssl.key.password = null
connect_1  |    ssl.keymanager.algorithm = SunX509
connect_1  |    ssl.keystore.location = null
connect_1  |    ssl.keystore.password = null
connect_1  |    ssl.keystore.type = JKS
connect_1  |    ssl.protocol = TLS
connect_1  |    ssl.provider = null
connect_1  |    ssl.secure.random.implementation = null
connect_1  |    ssl.trustmanager.algorithm = PKIX
connect_1  |    ssl.truststore.location = null
connect_1  |    ssl.truststore.password = null
connect_1  |    ssl.truststore.type = JKS
connect_1  |  (org.apache.kafka.clients.admin.AdminClientConfig:279)
connect_1  | [2019-07-01 12:39:07,739] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,739] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,741] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,742] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,742] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,742] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,742] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,742] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,743] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,743] WARN The configuration 'port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,743] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,744] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,744] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,745] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,745] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,747] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,747] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,747] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:07,748] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser:109)
connect_1  | [2019-07-01 12:39:07,749] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser:110)
kafka_1    | [2019-07-01 12:39:07,825] INFO [Admin Manager on Broker 0]: Error processing create topic request for topic connect-offsets with arguments (numPartitions=25, replicationFactor=1, replicasAssignments={}, configs={cleanup.policy=compact}) (kafka.server.AdminManager)
kafka_1    | org.apache.kafka.common.errors.TopicExistsException: Topic 'connect-offsets' already exists.
connect_1  | [2019-07-01 12:39:07,863] INFO ProducerConfig values:
connect_1  |    acks = all
connect_1  |    batch.size = 16384
connect_1  |    bootstrap.servers = [kafka:9092]
connect_1  |    buffer.memory = 33554432
connect_1  |    client.dns.lookup = default
connect_1  |    client.id =
connect_1  |    compression.type = none
connect_1  |    connections.max.idle.ms = 540000
connect_1  |    delivery.timeout.ms = 2147483647
connect_1  |    enable.idempotence = false
connect_1  |    interceptor.classes = []
connect_1  |    key.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
connect_1  |    linger.ms = 0
connect_1  |    max.block.ms = 60000
connect_1  |    max.in.flight.requests.per.connection = 1
connect_1  |    max.request.size = 1048576
connect_1  |    metadata.max.age.ms = 300000
connect_1  |    metric.reporters = []
connect_1  |    metrics.num.samples = 2
connect_1  |    metrics.recording.level = INFO
connect_1  |    metrics.sample.window.ms = 30000
connect_1  |    partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
connect_1  |    receive.buffer.bytes = 32768
connect_1  |    reconnect.backoff.max.ms = 1000
connect_1  |    reconnect.backoff.ms = 50
connect_1  |    request.timeout.ms = 30000
connect_1  |    retries = 2147483647
connect_1  |    retry.backoff.ms = 100
connect_1  |    sasl.client.callback.handler.class = null
connect_1  |    sasl.jaas.config = null
connect_1  |    sasl.kerberos.kinit.cmd = /usr/bin/kinit
connect_1  |    sasl.kerberos.min.time.before.relogin = 60000
connect_1  |    sasl.kerberos.service.name = null
connect_1  |    sasl.kerberos.ticket.renew.jitter = 0.05
connect_1  |    sasl.kerberos.ticket.renew.window.factor = 0.8
connect_1  |    sasl.login.callback.handler.class = null
connect_1  |    sasl.login.class = null
connect_1  |    sasl.login.refresh.buffer.seconds = 300
connect_1  |    sasl.login.refresh.min.period.seconds = 60
connect_1  |    sasl.login.refresh.window.factor = 0.8
connect_1  |    sasl.login.refresh.window.jitter = 0.05
connect_1  |    sasl.mechanism = GSSAPI
connect_1  |    security.protocol = PLAINTEXT
connect_1  |    send.buffer.bytes = 131072
connect_1  |    ssl.cipher.suites = null
connect_1  |    ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
connect_1  |    ssl.endpoint.identification.algorithm = https
connect_1  |    ssl.key.password = null
connect_1  |    ssl.keymanager.algorithm = SunX509
connect_1  |    ssl.keystore.location = null
connect_1  |    ssl.keystore.password = null
connect_1  |    ssl.keystore.type = JKS
connect_1  |    ssl.protocol = TLS
connect_1  |    ssl.provider = null
connect_1  |    ssl.secure.random.implementation = null
connect_1  |    ssl.trustmanager.algorithm = PKIX
connect_1  |    ssl.truststore.location = null
connect_1  |    ssl.truststore.password = null
connect_1  |    ssl.truststore.type = JKS
connect_1  |    transaction.timeout.ms = 60000
connect_1  |    transactional.id = null
connect_1  |    value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
connect_1  |  (org.apache.kafka.clients.producer.ProducerConfig:279)
connect_1  | [2019-07-01 12:39:07,935] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,936] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,936] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,936] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,936] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,937] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,937] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,938] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,939] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,939] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,939] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,940] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,941] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,942] WARN The configuration 'port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,943] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,944] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,944] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,945] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:07,945] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser:109)
connect_1  | [2019-07-01 12:39:07,945] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser:110)
connect_1  | [2019-07-01 12:39:07,960] INFO ConsumerConfig values:
connect_1  |    auto.commit.interval.ms = 5000
connect_1  |    auto.offset.reset = earliest
connect_1  |    bootstrap.servers = [kafka:9092]
connect_1  |    check.crcs = true
connect_1  |    client.dns.lookup = default
connect_1  |    client.id =
connect_1  |    connections.max.idle.ms = 540000
connect_1  |    default.api.timeout.ms = 60000
connect_1  |    enable.auto.commit = false
connect_1  |    exclude.internal.topics = true
connect_1  |    fetch.max.bytes = 52428800
connect_1  |    fetch.max.wait.ms = 500
connect_1  |    fetch.min.bytes = 1
connect_1  |    group.id = connect-cluster-A
connect_1  |    heartbeat.interval.ms = 3000
connect_1  |    interceptor.classes = []
connect_1  |    internal.leave.group.on.close = true
connect_1  |    isolation.level = read_uncommitted
connect_1  |    key.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
connect_1  |    max.partition.fetch.bytes = 1048576
connect_1  |    max.poll.interval.ms = 300000
connect_1  |    max.poll.records = 500
connect_1  |    metadata.max.age.ms = 300000
connect_1  |    metric.reporters = []
connect_1  |    metrics.num.samples = 2
connect_1  |    metrics.recording.level = INFO
connect_1  |    metrics.sample.window.ms = 30000
connect_1  |    partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
connect_1  |    receive.buffer.bytes = 65536
connect_1  |    reconnect.backoff.max.ms = 1000
connect_1  |    reconnect.backoff.ms = 50
connect_1  |    request.timeout.ms = 30000
connect_1  |    retry.backoff.ms = 100
connect_1  |    sasl.client.callback.handler.class = null
connect_1  |    sasl.jaas.config = null
connect_1  |    sasl.kerberos.kinit.cmd = /usr/bin/kinit
connect_1  |    sasl.kerberos.min.time.before.relogin = 60000
connect_1  |    sasl.kerberos.service.name = null
connect_1  |    sasl.kerberos.ticket.renew.jitter = 0.05
connect_1  |    sasl.kerberos.ticket.renew.window.factor = 0.8
connect_1  |    sasl.login.callback.handler.class = null
connect_1  |    sasl.login.class = null
connect_1  |    sasl.login.refresh.buffer.seconds = 300
connect_1  |    sasl.login.refresh.min.period.seconds = 60
connect_1  |    sasl.login.refresh.window.factor = 0.8
connect_1  |    sasl.login.refresh.window.jitter = 0.05
connect_1  |    sasl.mechanism = GSSAPI
connect_1  |    security.protocol = PLAINTEXT
connect_1  |    send.buffer.bytes = 131072
connect_1  |    session.timeout.ms = 10000
connect_1  |    ssl.cipher.suites = null
connect_1  |    ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
connect_1  |    ssl.endpoint.identification.algorithm = https
connect_1  |    ssl.key.password = null
connect_1  |    ssl.keymanager.algorithm = SunX509
connect_1  |    ssl.keystore.location = null
connect_1  |    ssl.keystore.password = null
connect_1  |    ssl.keystore.type = JKS
connect_1  |    ssl.protocol = TLS
connect_1  |    ssl.provider = null
connect_1  |    ssl.secure.random.implementation = null
connect_1  |    ssl.trustmanager.algorithm = PKIX
connect_1  |    ssl.truststore.location = null
connect_1  |    ssl.truststore.password = null
connect_1  |    ssl.truststore.type = JKS
connect_1  |    value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
connect_1  |  (org.apache.kafka.clients.consumer.ConsumerConfig:279)
connect_1  | [2019-07-01 12:39:07,998] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:07,999] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:07,999] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:07,999] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,000] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,000] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,001] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,001] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,002] WARN The configuration 'port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,002] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,003] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,003] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,005] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,005] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,006] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,006] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,006] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,007] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser:109)
connect_1  | [2019-07-01 12:39:08,007] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser:110)
connect_1  | [2019-07-01 12:39:08,020] INFO Cluster ID: BDDF9e57RLu8iD_aMyORAQ (org.apache.kafka.clients.Metadata:365)
connect_1  | [2019-07-01 12:39:08,098] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Subscribed to partition(s): connect-offsets-23, connect-offsets-17, connect-offsets-8, connect-offsets-11, connect-offsets-20, connect-offsets-2, connect-offsets-5, connect-offsets-14, connect-offsets-13, connect-offsets-4, connect-offsets-22, connect-offsets-16, connect-offsets-7, connect-offsets-10, connect-offsets-1, connect-offsets-19, connect-offsets-9, connect-offsets-18, connect-offsets-21, connect-offsets-12, connect-offsets-3, connect-offsets-15, connect-offsets-24, connect-offsets-6, connect-offsets-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1090)
connect_1  | [2019-07-01 12:39:08,109] INFO Cluster ID: BDDF9e57RLu8iD_aMyORAQ (org.apache.kafka.clients.Metadata:365)
connect_1  | [2019-07-01 12:39:08,245] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-10 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,247] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-8 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,248] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-14 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,248] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-12 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,253] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-2 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,255] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-0 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,256] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-6 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,256] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-4 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,259] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-24 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,259] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-18 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,260] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-16 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,260] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-22 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,260] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-20 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,261] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-9 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,261] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-7 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,261] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-13 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,262] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-11 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,262] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-1 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,263] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-5 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,263] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-3 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,263] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-23 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,264] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-17 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,265] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-15 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,266] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-21 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,266] INFO [Consumer clientId=consumer-1, groupId=connect-cluster-A] Resetting offset for partition connect-offsets-19 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,267] INFO Finished reading KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:158)
connect_1  | [2019-07-01 12:39:08,268] INFO Started KafkaBasedLog for topic connect-offsets (org.apache.kafka.connect.util.KafkaBasedLog:160)
connect_1  | [2019-07-01 12:39:08,268] INFO Finished reading offsets topic and starting KafkaOffsetBackingStore (org.apache.kafka.connect.storage.KafkaOffsetBackingStore:110)
connect_1  | [2019-07-01 12:39:08,269] INFO Worker started (org.apache.kafka.connect.runtime.Worker:167)
connect_1  | [2019-07-01 12:39:08,270] INFO Starting KafkaBasedLog with topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:125)
connect_1  | [2019-07-01 12:39:08,272] INFO AdminClientConfig values:
connect_1  |    bootstrap.servers = [kafka:9092]
connect_1  |    client.dns.lookup = default
connect_1  |    client.id =
connect_1  |    connections.max.idle.ms = 300000
connect_1  |    metadata.max.age.ms = 300000
connect_1  |    metric.reporters = []
connect_1  |    metrics.num.samples = 2
connect_1  |    metrics.recording.level = INFO
connect_1  |    metrics.sample.window.ms = 30000
connect_1  |    receive.buffer.bytes = 65536
connect_1  |    reconnect.backoff.max.ms = 1000
connect_1  |    reconnect.backoff.ms = 50
connect_1  |    request.timeout.ms = 120000
connect_1  |    retries = 5
connect_1  |    retry.backoff.ms = 100
connect_1  |    sasl.client.callback.handler.class = null
connect_1  |    sasl.jaas.config = null
connect_1  |    sasl.kerberos.kinit.cmd = /usr/bin/kinit
connect_1  |    sasl.kerberos.min.time.before.relogin = 60000
connect_1  |    sasl.kerberos.service.name = null
connect_1  |    sasl.kerberos.ticket.renew.jitter = 0.05
connect_1  |    sasl.kerberos.ticket.renew.window.factor = 0.8
connect_1  |    sasl.login.callback.handler.class = null
connect_1  |    sasl.login.class = null
connect_1  |    sasl.login.refresh.buffer.seconds = 300
connect_1  |    sasl.login.refresh.min.period.seconds = 60
connect_1  |    sasl.login.refresh.window.factor = 0.8
connect_1  |    sasl.login.refresh.window.jitter = 0.05
connect_1  |    sasl.mechanism = GSSAPI
connect_1  |    security.protocol = PLAINTEXT
connect_1  |    send.buffer.bytes = 131072
connect_1  |    ssl.cipher.suites = null
connect_1  |    ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
connect_1  |    ssl.endpoint.identification.algorithm = https
connect_1  |    ssl.key.password = null
connect_1  |    ssl.keymanager.algorithm = SunX509
connect_1  |    ssl.keystore.location = null
connect_1  |    ssl.keystore.password = null
connect_1  |    ssl.keystore.type = JKS
connect_1  |    ssl.protocol = TLS
connect_1  |    ssl.provider = null
connect_1  |    ssl.secure.random.implementation = null
connect_1  |    ssl.trustmanager.algorithm = PKIX
connect_1  |    ssl.truststore.location = null
connect_1  |    ssl.truststore.password = null
connect_1  |    ssl.truststore.type = JKS
connect_1  |  (org.apache.kafka.clients.admin.AdminClientConfig:279)
connect_1  | [2019-07-01 12:39:08,277] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,279] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,299] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,300] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,300] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,300] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,301] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,301] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,302] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,303] WARN The configuration 'port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,305] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,306] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,306] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,307] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,307] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,307] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,308] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,308] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,310] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser:109)
connect_1  | [2019-07-01 12:39:08,311] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser:110)
kafka_1    | [2019-07-01 12:39:08,375] INFO [Admin Manager on Broker 0]: Error processing create topic request for topic connect-status with arguments (numPartitions=5, replicationFactor=1, replicasAssignments={}, configs={cleanup.policy=compact}) (kafka.server.AdminManager)
kafka_1    | org.apache.kafka.common.errors.TopicExistsException: Topic 'connect-status' already exists.
connect_1  | [2019-07-01 12:39:08,382] INFO ProducerConfig values:
connect_1  |    acks = all
connect_1  |    batch.size = 16384
connect_1  |    bootstrap.servers = [kafka:9092]
connect_1  |    buffer.memory = 33554432
connect_1  |    client.dns.lookup = default
connect_1  |    client.id =
connect_1  |    compression.type = none
connect_1  |    connections.max.idle.ms = 540000
connect_1  |    delivery.timeout.ms = 120000
connect_1  |    enable.idempotence = false
connect_1  |    interceptor.classes = []
connect_1  |    key.serializer = class org.apache.kafka.common.serialization.StringSerializer
connect_1  |    linger.ms = 0
connect_1  |    max.block.ms = 60000
connect_1  |    max.in.flight.requests.per.connection = 1
connect_1  |    max.request.size = 1048576
connect_1  |    metadata.max.age.ms = 300000
connect_1  |    metric.reporters = []
connect_1  |    metrics.num.samples = 2
connect_1  |    metrics.recording.level = INFO
connect_1  |    metrics.sample.window.ms = 30000
connect_1  |    partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
connect_1  |    receive.buffer.bytes = 32768
connect_1  |    reconnect.backoff.max.ms = 1000
connect_1  |    reconnect.backoff.ms = 50
connect_1  |    request.timeout.ms = 30000
connect_1  |    retries = 0
connect_1  |    retry.backoff.ms = 100
connect_1  |    sasl.client.callback.handler.class = null
connect_1  |    sasl.jaas.config = null
connect_1  |    sasl.kerberos.kinit.cmd = /usr/bin/kinit
connect_1  |    sasl.kerberos.min.time.before.relogin = 60000
connect_1  |    sasl.kerberos.service.name = null
connect_1  |    sasl.kerberos.ticket.renew.jitter = 0.05
connect_1  |    sasl.kerberos.ticket.renew.window.factor = 0.8
connect_1  |    sasl.login.callback.handler.class = null
connect_1  |    sasl.login.class = null
connect_1  |    sasl.login.refresh.buffer.seconds = 300
connect_1  |    sasl.login.refresh.min.period.seconds = 60
connect_1  |    sasl.login.refresh.window.factor = 0.8
connect_1  |    sasl.login.refresh.window.jitter = 0.05
connect_1  |    sasl.mechanism = GSSAPI
connect_1  |    security.protocol = PLAINTEXT
connect_1  |    send.buffer.bytes = 131072
connect_1  |    ssl.cipher.suites = null
connect_1  |    ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
connect_1  |    ssl.endpoint.identification.algorithm = https
connect_1  |    ssl.key.password = null
connect_1  |    ssl.keymanager.algorithm = SunX509
connect_1  |    ssl.keystore.location = null
connect_1  |    ssl.keystore.password = null
connect_1  |    ssl.keystore.type = JKS
connect_1  |    ssl.protocol = TLS
connect_1  |    ssl.provider = null
connect_1  |    ssl.secure.random.implementation = null
connect_1  |    ssl.trustmanager.algorithm = PKIX
connect_1  |    ssl.truststore.location = null
connect_1  |    ssl.truststore.password = null
connect_1  |    ssl.truststore.type = JKS
connect_1  |    transaction.timeout.ms = 60000
connect_1  |    transactional.id = null
connect_1  |    value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
connect_1  |  (org.apache.kafka.clients.producer.ProducerConfig:279)
connect_1  | [2019-07-01 12:39:08,387] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,388] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,388] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,389] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,389] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,390] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,390] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,390] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,391] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,391] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,391] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,392] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,392] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,393] WARN The configuration 'port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,393] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,393] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,393] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,394] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,394] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser:109)
connect_1  | [2019-07-01 12:39:08,394] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser:110)
connect_1  | [2019-07-01 12:39:08,395] INFO ConsumerConfig values:
connect_1  |    auto.commit.interval.ms = 5000
connect_1  |    auto.offset.reset = earliest
connect_1  |    bootstrap.servers = [kafka:9092]
connect_1  |    check.crcs = true
connect_1  |    client.dns.lookup = default
connect_1  |    client.id =
connect_1  |    connections.max.idle.ms = 540000
connect_1  |    default.api.timeout.ms = 60000
connect_1  |    enable.auto.commit = false
connect_1  |    exclude.internal.topics = true
connect_1  |    fetch.max.bytes = 52428800
connect_1  |    fetch.max.wait.ms = 500
connect_1  |    fetch.min.bytes = 1
connect_1  |    group.id = connect-cluster-A
connect_1  |    heartbeat.interval.ms = 3000
connect_1  |    interceptor.classes = []
connect_1  |    internal.leave.group.on.close = true
connect_1  |    isolation.level = read_uncommitted
connect_1  |    key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
connect_1  |    max.partition.fetch.bytes = 1048576
connect_1  |    max.poll.interval.ms = 300000
connect_1  |    max.poll.records = 500
connect_1  |    metadata.max.age.ms = 300000
connect_1  |    metric.reporters = []
connect_1  |    metrics.num.samples = 2
connect_1  |    metrics.recording.level = INFO
connect_1  |    metrics.sample.window.ms = 30000
connect_1  |    partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
connect_1  |    receive.buffer.bytes = 65536
connect_1  |    reconnect.backoff.max.ms = 1000
connect_1  |    reconnect.backoff.ms = 50
connect_1  |    request.timeout.ms = 30000
connect_1  |    retry.backoff.ms = 100
connect_1  |    sasl.client.callback.handler.class = null
connect_1  |    sasl.jaas.config = null
connect_1  |    sasl.kerberos.kinit.cmd = /usr/bin/kinit
connect_1  |    sasl.kerberos.min.time.before.relogin = 60000
connect_1  |    sasl.kerberos.service.name = null
connect_1  |    sasl.kerberos.ticket.renew.jitter = 0.05
connect_1  |    sasl.kerberos.ticket.renew.window.factor = 0.8
connect_1  |    sasl.login.callback.handler.class = null
connect_1  |    sasl.login.class = null
connect_1  |    sasl.login.refresh.buffer.seconds = 300
connect_1  |    sasl.login.refresh.min.period.seconds = 60
connect_1  |    sasl.login.refresh.window.factor = 0.8
connect_1  |    sasl.login.refresh.window.jitter = 0.05
connect_1  |    sasl.mechanism = GSSAPI
connect_1  |    security.protocol = PLAINTEXT
connect_1  |    send.buffer.bytes = 131072
connect_1  |    session.timeout.ms = 10000
connect_1  |    ssl.cipher.suites = null
connect_1  |    ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
connect_1  |    ssl.endpoint.identification.algorithm = https
connect_1  |    ssl.key.password = null
connect_1  |    ssl.keymanager.algorithm = SunX509
connect_1  |    ssl.keystore.location = null
connect_1  |    ssl.keystore.password = null
connect_1  |    ssl.keystore.type = JKS
connect_1  |    ssl.protocol = TLS
connect_1  |    ssl.provider = null
connect_1  |    ssl.secure.random.implementation = null
connect_1  |    ssl.trustmanager.algorithm = PKIX
connect_1  |    ssl.truststore.location = null
connect_1  |    ssl.truststore.password = null
connect_1  |    ssl.truststore.type = JKS
connect_1  |    value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
connect_1  |  (org.apache.kafka.clients.consumer.ConsumerConfig:279)
connect_1  | [2019-07-01 12:39:08,400] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,401] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,402] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,403] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,403] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,404] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,404] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,404] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,405] WARN The configuration 'port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,405] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,406] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,406] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,407] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,407] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,408] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,408] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,408] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,409] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser:109)
connect_1  | [2019-07-01 12:39:08,409] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser:110)
connect_1  | [2019-07-01 12:39:08,425] INFO [Consumer clientId=consumer-2, groupId=connect-cluster-A] Subscribed to partition(s): connect-status-2, connect-status-4, connect-status-1, connect-status-3, connect-status-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1090)
connect_1  | [2019-07-01 12:39:08,428] INFO Cluster ID: BDDF9e57RLu8iD_aMyORAQ (org.apache.kafka.clients.Metadata:365)
connect_1  | [2019-07-01 12:39:08,449] INFO [Consumer clientId=consumer-2, groupId=connect-cluster-A] Resetting offset for partition connect-status-1 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,450] INFO [Consumer clientId=consumer-2, groupId=connect-cluster-A] Resetting offset for partition connect-status-2 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,450] INFO [Consumer clientId=consumer-2, groupId=connect-cluster-A] Resetting offset for partition connect-status-0 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,452] INFO [Consumer clientId=consumer-2, groupId=connect-cluster-A] Resetting offset for partition connect-status-3 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,453] INFO [Consumer clientId=consumer-2, groupId=connect-cluster-A] Resetting offset for partition connect-status-4 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,501] INFO Cluster ID: BDDF9e57RLu8iD_aMyORAQ (org.apache.kafka.clients.Metadata:365)
connect_1  | [2019-07-01 12:39:08,543] INFO Finished reading KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:158)
connect_1  | [2019-07-01 12:39:08,543] INFO Started KafkaBasedLog for topic connect-status (org.apache.kafka.connect.util.KafkaBasedLog:160)
connect_1  | [2019-07-01 12:39:08,544] INFO Starting KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:248)
connect_1  | [2019-07-01 12:39:08,545] INFO Starting KafkaBasedLog with topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:125)
connect_1  | [2019-07-01 12:39:08,548] INFO AdminClientConfig values:
connect_1  |    bootstrap.servers = [kafka:9092]
connect_1  |    client.dns.lookup = default
connect_1  |    client.id =
connect_1  |    connections.max.idle.ms = 300000
connect_1  |    metadata.max.age.ms = 300000
connect_1  |    metric.reporters = []
connect_1  |    metrics.num.samples = 2
connect_1  |    metrics.recording.level = INFO
connect_1  |    metrics.sample.window.ms = 30000
connect_1  |    receive.buffer.bytes = 65536
connect_1  |    reconnect.backoff.max.ms = 1000
connect_1  |    reconnect.backoff.ms = 50
connect_1  |    request.timeout.ms = 120000
connect_1  |    retries = 5
connect_1  |    retry.backoff.ms = 100
connect_1  |    sasl.client.callback.handler.class = null
connect_1  |    sasl.jaas.config = null
connect_1  |    sasl.kerberos.kinit.cmd = /usr/bin/kinit
connect_1  |    sasl.kerberos.min.time.before.relogin = 60000
connect_1  |    sasl.kerberos.service.name = null
connect_1  |    sasl.kerberos.ticket.renew.jitter = 0.05
connect_1  |    sasl.kerberos.ticket.renew.window.factor = 0.8
connect_1  |    sasl.login.callback.handler.class = null
connect_1  |    sasl.login.class = null
connect_1  |    sasl.login.refresh.buffer.seconds = 300
connect_1  |    sasl.login.refresh.min.period.seconds = 60
connect_1  |    sasl.login.refresh.window.factor = 0.8
connect_1  |    sasl.login.refresh.window.jitter = 0.05
connect_1  |    sasl.mechanism = GSSAPI
connect_1  |    security.protocol = PLAINTEXT
connect_1  |    send.buffer.bytes = 131072
connect_1  |    ssl.cipher.suites = null
connect_1  |    ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
connect_1  |    ssl.endpoint.identification.algorithm = https
connect_1  |    ssl.key.password = null
connect_1  |    ssl.keymanager.algorithm = SunX509
connect_1  |    ssl.keystore.location = null
connect_1  |    ssl.keystore.password = null
connect_1  |    ssl.keystore.type = JKS
connect_1  |    ssl.protocol = TLS
connect_1  |    ssl.provider = null
connect_1  |    ssl.secure.random.implementation = null
connect_1  |    ssl.trustmanager.algorithm = PKIX
connect_1  |    ssl.truststore.location = null
connect_1  |    ssl.truststore.password = null
connect_1  |    ssl.truststore.type = JKS
connect_1  |  (org.apache.kafka.clients.admin.AdminClientConfig:279)
connect_1  | [2019-07-01 12:39:08,550] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,550] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,551] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,551] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,555] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,555] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,556] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,557] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,557] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,558] WARN The configuration 'port' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,558] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,558] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,559] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,559] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,560] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,560] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,560] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,561] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.admin.AdminClientConfig:287)
connect_1  | [2019-07-01 12:39:08,562] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser:109)
connect_1  | [2019-07-01 12:39:08,564] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser:110)
kafka_1    | [2019-07-01 12:39:08,591] INFO [Admin Manager on Broker 0]: Error processing create topic request for topic connect-configs with arguments (numPartitions=1, replicationFactor=1, replicasAssignments={}, configs={cleanup.policy=compact}) (kafka.server.AdminManager)
kafka_1    | org.apache.kafka.common.errors.TopicExistsException: Topic 'connect-configs' already exists.
connect_1  | [2019-07-01 12:39:08,594] INFO ProducerConfig values:
connect_1  |    acks = all
connect_1  |    batch.size = 16384
connect_1  |    bootstrap.servers = [kafka:9092]
connect_1  |    buffer.memory = 33554432
connect_1  |    client.dns.lookup = default
connect_1  |    client.id =
connect_1  |    compression.type = none
connect_1  |    connections.max.idle.ms = 540000
connect_1  |    delivery.timeout.ms = 2147483647
connect_1  |    enable.idempotence = false
connect_1  |    interceptor.classes = []
connect_1  |    key.serializer = class org.apache.kafka.common.serialization.StringSerializer
connect_1  |    linger.ms = 0
connect_1  |    max.block.ms = 60000
connect_1  |    max.in.flight.requests.per.connection = 1
connect_1  |    max.request.size = 1048576
connect_1  |    metadata.max.age.ms = 300000
connect_1  |    metric.reporters = []
connect_1  |    metrics.num.samples = 2
connect_1  |    metrics.recording.level = INFO
connect_1  |    metrics.sample.window.ms = 30000
connect_1  |    partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
connect_1  |    receive.buffer.bytes = 32768
connect_1  |    reconnect.backoff.max.ms = 1000
connect_1  |    reconnect.backoff.ms = 50
connect_1  |    request.timeout.ms = 30000
connect_1  |    retries = 2147483647
connect_1  |    retry.backoff.ms = 100
connect_1  |    sasl.client.callback.handler.class = null
connect_1  |    sasl.jaas.config = null
connect_1  |    sasl.kerberos.kinit.cmd = /usr/bin/kinit
connect_1  |    sasl.kerberos.min.time.before.relogin = 60000
connect_1  |    sasl.kerberos.service.name = null
connect_1  |    sasl.kerberos.ticket.renew.jitter = 0.05
connect_1  |    sasl.kerberos.ticket.renew.window.factor = 0.8
connect_1  |    sasl.login.callback.handler.class = null
connect_1  |    sasl.login.class = null
connect_1  |    sasl.login.refresh.buffer.seconds = 300
connect_1  |    sasl.login.refresh.min.period.seconds = 60
connect_1  |    sasl.login.refresh.window.factor = 0.8
connect_1  |    sasl.login.refresh.window.jitter = 0.05
connect_1  |    sasl.mechanism = GSSAPI
connect_1  |    security.protocol = PLAINTEXT
connect_1  |    send.buffer.bytes = 131072
connect_1  |    ssl.cipher.suites = null
connect_1  |    ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
connect_1  |    ssl.endpoint.identification.algorithm = https
connect_1  |    ssl.key.password = null
connect_1  |    ssl.keymanager.algorithm = SunX509
connect_1  |    ssl.keystore.location = null
connect_1  |    ssl.keystore.password = null
connect_1  |    ssl.keystore.type = JKS
connect_1  |    ssl.protocol = TLS
connect_1  |    ssl.provider = null
connect_1  |    ssl.secure.random.implementation = null
connect_1  |    ssl.trustmanager.algorithm = PKIX
connect_1  |    ssl.truststore.location = null
connect_1  |    ssl.truststore.password = null
connect_1  |    ssl.truststore.type = JKS
connect_1  |    transaction.timeout.ms = 60000
connect_1  |    transactional.id = null
connect_1  |    value.serializer = class org.apache.kafka.common.serialization.ByteArraySerializer
connect_1  |  (org.apache.kafka.clients.producer.ProducerConfig:279)
connect_1  | [2019-07-01 12:39:08,602] WARN The configuration 'group.id' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,603] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,603] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,604] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,604] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,605] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,605] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,605] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,606] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,606] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,607] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,607] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,607] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,607] WARN The configuration 'port' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,608] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,608] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,608] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,608] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.producer.ProducerConfig:287)
connect_1  | [2019-07-01 12:39:08,609] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser:109)
connect_1  | [2019-07-01 12:39:08,609] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser:110)
connect_1  | [2019-07-01 12:39:08,610] INFO ConsumerConfig values:
connect_1  |    auto.commit.interval.ms = 5000
connect_1  |    auto.offset.reset = earliest
connect_1  |    bootstrap.servers = [kafka:9092]
connect_1  |    check.crcs = true
connect_1  |    client.dns.lookup = default
connect_1  |    client.id =
connect_1  |    connections.max.idle.ms = 540000
connect_1  |    default.api.timeout.ms = 60000
connect_1  |    enable.auto.commit = false
connect_1  |    exclude.internal.topics = true
connect_1  |    fetch.max.bytes = 52428800
connect_1  |    fetch.max.wait.ms = 500
connect_1  |    fetch.min.bytes = 1
connect_1  |    group.id = connect-cluster-A
connect_1  |    heartbeat.interval.ms = 3000
connect_1  |    interceptor.classes = []
connect_1  |    internal.leave.group.on.close = true
connect_1  |    isolation.level = read_uncommitted
connect_1  |    key.deserializer = class org.apache.kafka.common.serialization.StringDeserializer
connect_1  |    max.partition.fetch.bytes = 1048576
connect_1  |    max.poll.interval.ms = 300000
connect_1  |    max.poll.records = 500
connect_1  |    metadata.max.age.ms = 300000
connect_1  |    metric.reporters = []
connect_1  |    metrics.num.samples = 2
connect_1  |    metrics.recording.level = INFO
connect_1  |    metrics.sample.window.ms = 30000
connect_1  |    partition.assignment.strategy = [class org.apache.kafka.clients.consumer.RangeAssignor]
connect_1  |    receive.buffer.bytes = 65536
connect_1  |    reconnect.backoff.max.ms = 1000
connect_1  |    reconnect.backoff.ms = 50
connect_1  |    request.timeout.ms = 30000
connect_1  |    retry.backoff.ms = 100
connect_1  |    sasl.client.callback.handler.class = null
connect_1  |    sasl.jaas.config = null
connect_1  |    sasl.kerberos.kinit.cmd = /usr/bin/kinit
connect_1  |    sasl.kerberos.min.time.before.relogin = 60000
connect_1  |    sasl.kerberos.service.name = null
connect_1  |    sasl.kerberos.ticket.renew.jitter = 0.05
connect_1  |    sasl.kerberos.ticket.renew.window.factor = 0.8
connect_1  |    sasl.login.callback.handler.class = null
connect_1  |    sasl.login.class = null
connect_1  |    sasl.login.refresh.buffer.seconds = 300
connect_1  |    sasl.login.refresh.min.period.seconds = 60
connect_1  |    sasl.login.refresh.window.factor = 0.8
connect_1  |    sasl.login.refresh.window.jitter = 0.05
connect_1  |    sasl.mechanism = GSSAPI
connect_1  |    security.protocol = PLAINTEXT
connect_1  |    send.buffer.bytes = 131072
connect_1  |    session.timeout.ms = 10000
connect_1  |    ssl.cipher.suites = null
connect_1  |    ssl.enabled.protocols = [TLSv1.2, TLSv1.1, TLSv1]
connect_1  |    ssl.endpoint.identification.algorithm = https
connect_1  |    ssl.key.password = null
connect_1  |    ssl.keymanager.algorithm = SunX509
connect_1  |    ssl.keystore.location = null
connect_1  |    ssl.keystore.password = null
connect_1  |    ssl.keystore.type = JKS
connect_1  |    ssl.protocol = TLS
connect_1  |    ssl.provider = null
connect_1  |    ssl.secure.random.implementation = null
connect_1  |    ssl.trustmanager.algorithm = PKIX
connect_1  |    ssl.truststore.location = null
connect_1  |    ssl.truststore.password = null
connect_1  |    ssl.truststore.type = JKS
connect_1  |    value.deserializer = class org.apache.kafka.common.serialization.ByteArrayDeserializer
connect_1  |  (org.apache.kafka.clients.consumer.ConsumerConfig:279)
connect_1  | [2019-07-01 12:39:08,614] WARN The configuration 'config.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,615] WARN The configuration 'status.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,615] WARN The configuration 'plugin.path' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,616] WARN The configuration 'internal.key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,621] WARN The configuration 'config.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,621] WARN The configuration 'offset.flush.interval.ms' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,621] WARN The configuration 'internal.key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,622] WARN The configuration 'key.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,622] WARN The configuration 'port' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,622] WARN The configuration 'internal.value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,622] WARN The configuration 'status.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,623] WARN The configuration 'value.converter.schemas.enable' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,623] WARN The configuration 'internal.value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,623] WARN The configuration 'offset.storage.replication.factor' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,623] WARN The configuration 'offset.storage.topic' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,623] WARN The configuration 'value.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,624] WARN The configuration 'key.converter' was supplied but isn't a known config. (org.apache.kafka.clients.consumer.ConsumerConfig:287)
connect_1  | [2019-07-01 12:39:08,624] INFO Kafka version: 2.2.0 (org.apache.kafka.common.utils.AppInfoParser:109)
connect_1  | [2019-07-01 12:39:08,624] INFO Kafka commitId: 05fcfde8f69b0349 (org.apache.kafka.common.utils.AppInfoParser:110)
connect_1  | [2019-07-01 12:39:08,644] INFO [Consumer clientId=consumer-3, groupId=connect-cluster-A] Subscribed to partition(s): connect-configs-0 (org.apache.kafka.clients.consumer.KafkaConsumer:1090)
connect_1  | [2019-07-01 12:39:08,647] INFO Cluster ID: BDDF9e57RLu8iD_aMyORAQ (org.apache.kafka.clients.Metadata:365)
connect_1  | [2019-07-01 12:39:08,654] INFO [Consumer clientId=consumer-3, groupId=connect-cluster-A] Resetting offset for partition connect-configs-0 to offset 0. (org.apache.kafka.clients.consumer.internals.Fetcher:584)
connect_1  | [2019-07-01 12:39:08,666] INFO Finished reading KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:158)
connect_1  | [2019-07-01 12:39:08,667] INFO Started KafkaBasedLog for topic connect-configs (org.apache.kafka.connect.util.KafkaBasedLog:160)
connect_1  | [2019-07-01 12:39:08,667] INFO Started KafkaConfigBackingStore (org.apache.kafka.connect.storage.KafkaConfigBackingStore:253)
connect_1  | [2019-07-01 12:39:08,668] INFO Herder started (org.apache.kafka.connect.runtime.distributed.DistributedHerder:216)
connect_1  | [2019-07-01 12:39:08,678] INFO Cluster ID: BDDF9e57RLu8iD_aMyORAQ (org.apache.kafka.clients.Metadata:365)
connect_1  | [2019-07-01 12:39:08,683] INFO [Worker clientId=connect-1, groupId=connect-cluster-A] Discovered group coordinator kafka:9092 (id: 2147483647 rack: null) (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:675)
connect_1  | [2019-07-01 12:39:08,685] INFO [Worker clientId=connect-1, groupId=connect-cluster-A] (Re-)joining group (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:491)
kafka_1    | [2019-07-01 12:39:08,700] INFO [GroupCoordinator 0]: Preparing to restabilize group connect-cluster-A with old generation 11 (kafka.coordinator.GroupCoordinator)
kafka_1    | [2019-07-01 12:39:08,713] INFO [GroupCoordinator 0]: Stabilized group connect-cluster-A generation 12 (kafka.coordinator.GroupCoordinator)
connect_1  | [2019-07-01 12:39:08,716] INFO Cluster ID: BDDF9e57RLu8iD_aMyORAQ (org.apache.kafka.clients.Metadata:365)
kafka_1    | [2019-07-01 12:39:08,729] INFO [GroupCoordinator 0]: Assignment received from leader for group connect-cluster-A for generation 12 (kafka.coordinator.GroupCoordinator)
connect_1  | [2019-07-01 12:39:08,775] INFO [Worker clientId=connect-1, groupId=connect-cluster-A] Successfully joined group with generation 12 (org.apache.kafka.clients.consumer.internals.AbstractCoordinator:455)
connect_1  | [2019-07-01 12:39:08,777] INFO Joined group and got assignment: Assignment{error=0, leader='connect-1-6bbd4dc0-ed15-4d17-8373-304bbad4803e', leaderUrl='http://172.21.0.4:8083/', offset=1, connectorIds=[jdbc-source-connector], taskIds=[]} (org.apache.kafka.connect.runtime.distributed.DistributedHerder:1216)
connect_1  | [2019-07-01 12:39:08,778] WARN Catching up to assignment's config offset. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:775)
connect_1  | [2019-07-01 12:39:08,779] INFO Current config state offset -1 is behind group assignment 1, reading to end of config log (org.apache.kafka.connect.runtime.distributed.DistributedHerder:820)
connect_1  | [2019-07-01 12:39:09,168] INFO Finished reading to end of log and updated config snapshot, new config log offset: 1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:824)
connect_1  | [2019-07-01 12:39:09,168] INFO Starting connectors and tasks using config offset 1 (org.apache.kafka.connect.runtime.distributed.DistributedHerder:850)
connect_1  | [2019-07-01 12:39:09,170] INFO Starting connector jdbc-source-connector (org.apache.kafka.connect.runtime.distributed.DistributedHerder:904)
connect_1  | [2019-07-01 12:39:09,175] INFO ConnectorConfig values:
connect_1  |    config.action.reload = restart
connect_1  |    connector.class = com.it.ibm.kafka.connectors.JdbcSourceConnector
connect_1  |    errors.log.enable = false
connect_1  |    errors.log.include.messages = false
connect_1  |    errors.retry.delay.max.ms = 60000
connect_1  |    errors.retry.timeout = 0
connect_1  |    errors.tolerance = none
connect_1  |    header.converter = null
connect_1  |    key.converter = null
connect_1  |    name = jdbc-source-connector
connect_1  |    tasks.max = 10
connect_1  |    transforms = []
connect_1  |    value.converter = null
connect_1  |  (org.apache.kafka.connect.runtime.ConnectorConfig:279)
connect_1  | [2019-07-01 12:39:09,176] INFO EnrichedConnectorConfig values:
connect_1  |    config.action.reload = restart
connect_1  |    connector.class = com.it.ibm.kafka.connectors.JdbcSourceConnector
connect_1  |    errors.log.enable = false
connect_1  |    errors.log.include.messages = false
connect_1  |    errors.retry.delay.max.ms = 60000
connect_1  |    errors.retry.timeout = 0
connect_1  |    errors.tolerance = none
connect_1  |    header.converter = null
connect_1  |    key.converter = null
connect_1  |    name = jdbc-source-connector
connect_1  |    tasks.max = 10
connect_1  |    transforms = []
connect_1  |    value.converter = null
connect_1  |  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:279)
connect_1  | [2019-07-01 12:39:09,176] INFO Creating connector jdbc-source-connector of type com.it.ibm.kafka.connectors.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:225)
connect_1  | [DEBUG] 2019-07-01 12:39:09.185 [pool-7-thread-1] JdbcSourceConnector - version source
connect_1  | [DEBUG] 2019-07-01 12:39:09.186 [pool-7-thread-1] JdbcSourceConnector - version source
connect_1  | [2019-07-01 12:39:09,187] INFO Instantiated connector jdbc-source-connector with version N/A of type class com.it.ibm.kafka.connectors.JdbcSourceConnector (org.apache.kafka.connect.runtime.Worker:228)
connect_1  | [DEBUG] 2019-07-01 12:39:09.188 [pool-7-thread-1] JdbcSourceConnector - start
connect_1  | [DEBUG] 2019-07-01 12:39:09.189 [pool-7-thread-1] JdbcSourceConnectorConfig - JdbcSourceConnectorConfig conf
connect_1  | [2019-07-01 12:39:09,189] INFO JdbcSourceConnectorConfig values:
connect_1  |    connection.url = mysql://fakehost:9000
connect_1  |  (com.it.ibm.kafka.connectors.source.JdbcSourceConnectorConfig:279)
connect_1  | [DEBUG] 2019-07-01 12:39:09.189 [pool-7-thread-1] JdbcSourceConnectorConfig - JdbcSourceConnectorConfig 1
connect_1  | [DEBUG] 2019-07-01 12:39:09.190 [pool-7-thread-1] JdbcSourceConnectorConfig - JdbcSourceConnectorConfig
connect_1  | [DEBUG] 2019-07-01 12:39:09.190 [pool-7-thread-1] JdbcSourceConnectorConfig - {connector.class=com.it.ibm.kafka.connectors.JdbcSourceConnector, flush.size=100, tasks.max=10, topics=test-topic, name=jdbc-source-connector, rotate.interval.ms=1000, connection.url=mysql://fakehost:9000}
connect_1  | [DEBUG] 2019-07-01 12:39:09.191 [pool-7-thread-1] JdbcSourceConnectorConfig - JdbcSourceConnectorConfig - end
connect_1  | [2019-07-01 12:39:09,250] INFO Finished creating connector jdbc-source-connector (org.apache.kafka.connect.runtime.Worker:247)
connect_1  | [2019-07-01 12:39:09,258] INFO SourceConnectorConfig values:
connect_1  |    config.action.reload = restart
connect_1  |    connector.class = com.it.ibm.kafka.connectors.JdbcSourceConnector
connect_1  |    errors.log.enable = false
connect_1  |    errors.log.include.messages = false
connect_1  |    errors.retry.delay.max.ms = 60000
connect_1  |    errors.retry.timeout = 0
connect_1  |    errors.tolerance = none
connect_1  |    header.converter = null
connect_1  |    key.converter = null
connect_1  |    name = jdbc-source-connector
connect_1  |    tasks.max = 10
connect_1  |    transforms = []
connect_1  |    value.converter = null
connect_1  |  (org.apache.kafka.connect.runtime.SourceConnectorConfig:279)
connect_1  | [2019-07-01 12:39:09,259] INFO EnrichedConnectorConfig values:
connect_1  |    config.action.reload = restart
connect_1  |    connector.class = com.it.ibm.kafka.connectors.JdbcSourceConnector
connect_1  |    errors.log.enable = false
connect_1  |    errors.log.include.messages = false
connect_1  |    errors.retry.delay.max.ms = 60000
connect_1  |    errors.retry.timeout = 0
connect_1  |    errors.tolerance = none
connect_1  |    header.converter = null
connect_1  |    key.converter = null
connect_1  |    name = jdbc-source-connector
connect_1  |    tasks.max = 10
connect_1  |    transforms = []
connect_1  |    value.converter = null
connect_1  |  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:279)
connect_1  | [DEBUG] 2019-07-01 12:39:09.259 [pool-7-thread-1] JdbcSourceConnector - taskClass
connect_1  | [2019-07-01 12:39:09,260] ERROR Failed to reconfigure connector's tasks, retrying after backoff: (org.apache.kafka.connect.runtime.distributed.DistributedHerder:958)
connect_1  | java.lang.NullPointerException
connect_1  |    at org.apache.kafka.connect.runtime.Worker.connectorTaskConfigs(Worker.java:294)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnector(DistributedHerder.java:997)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnectorTasksWithRetry(DistributedHerder.java:950)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.startConnector(DistributedHerder.java:914)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.access$1300(DistributedHerder.java:110)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder$15.call(DistributedHerder.java:924)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder$15.call(DistributedHerder.java:920)
connect_1  |    at java.util.concurrent.FutureTask.run(FutureTask.java:266)
connect_1  |    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
connect_1  |    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
connect_1  |    at java.lang.Thread.run(Thread.java:745)
connect_1  | [2019-07-01 12:39:09,271] INFO Finished starting connectors and tasks (org.apache.kafka.connect.runtime.distributed.DistributedHerder:860)
connect_1  | [2019-07-01 12:39:09,521] INFO SourceConnectorConfig values:
connect_1  |    config.action.reload = restart
connect_1  |    connector.class = com.it.ibm.kafka.connectors.JdbcSourceConnector
connect_1  |    errors.log.enable = false
connect_1  |    errors.log.include.messages = false
connect_1  |    errors.retry.delay.max.ms = 60000
connect_1  |    errors.retry.timeout = 0
connect_1  |    errors.tolerance = none
connect_1  |    header.converter = null
connect_1  |    key.converter = null
connect_1  |    name = jdbc-source-connector
connect_1  |    tasks.max = 10
connect_1  |    transforms = []
connect_1  |    value.converter = null
connect_1  |  (org.apache.kafka.connect.runtime.SourceConnectorConfig:279)
connect_1  | [2019-07-01 12:39:09,522] INFO EnrichedConnectorConfig values:
connect_1  |    config.action.reload = restart
connect_1  |    connector.class = com.it.ibm.kafka.connectors.JdbcSourceConnector
connect_1  |    errors.log.enable = false
connect_1  |    errors.log.include.messages = false
connect_1  |    errors.retry.delay.max.ms = 60000
connect_1  |    errors.retry.timeout = 0
connect_1  |    errors.tolerance = none
connect_1  |    header.converter = null
connect_1  |    key.converter = null
connect_1  |    name = jdbc-source-connector
connect_1  |    tasks.max = 10
connect_1  |    transforms = []
connect_1  |    value.converter = null
connect_1  |  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:279)
connect_1  | [DEBUG] 2019-07-01 12:39:09.523 [DistributedHerder] JdbcSourceConnector - taskClass
connect_1  | [2019-07-01 12:39:09,523] ERROR Failed to reconfigure connector's tasks, retrying after backoff: (org.apache.kafka.connect.runtime.distributed.DistributedHerder:958)
connect_1  | java.lang.NullPointerException
connect_1  |    at org.apache.kafka.connect.runtime.Worker.connectorTaskConfigs(Worker.java:294)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnector(DistributedHerder.java:997)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnectorTasksWithRetry(DistributedHerder.java:950)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.access$900(DistributedHerder.java:110)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder$17$1.call(DistributedHerder.java:963)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder$17$1.call(DistributedHerder.java:960)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.tick(DistributedHerder.java:270)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:219)
connect_1  |    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
connect_1  |    at java.util.concurrent.FutureTask.run(FutureTask.java:266)
connect_1  |    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
connect_1  |    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
connect_1  |    at java.lang.Thread.run(Thread.java:745)
connect_1  | [2019-07-01 12:39:09,524] ERROR Unexpected error during connector task reconfiguration:  (org.apache.kafka.connect.runtime.distributed.DistributedHerder:969)
connect_1  | [2019-07-01 12:39:09,524] ERROR Task reconfiguration for jdbc-source-connector failed unexpectedly, this connector will not be properly reconfigured unless manually triggered. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:970)
connect_1  | [2019-07-01 12:39:09,776] INFO SourceConnectorConfig values:
connect_1  |    config.action.reload = restart
connect_1  |    connector.class = com.it.ibm.kafka.connectors.JdbcSourceConnector
connect_1  |    errors.log.enable = false
connect_1  |    errors.log.include.messages = false
connect_1  |    errors.retry.delay.max.ms = 60000
connect_1  |    errors.retry.timeout = 0
connect_1  |    errors.tolerance = none
connect_1  |    header.converter = null
connect_1  |    key.converter = null
connect_1  |    name = jdbc-source-connector
connect_1  |    tasks.max = 10
connect_1  |    transforms = []
connect_1  |    value.converter = null
connect_1  |  (org.apache.kafka.connect.runtime.SourceConnectorConfig:279)
connect_1  | [2019-07-01 12:39:09,777] INFO EnrichedConnectorConfig values:
connect_1  |    config.action.reload = restart
connect_1  |    connector.class = com.it.ibm.kafka.connectors.JdbcSourceConnector
connect_1  |    errors.log.enable = false
connect_1  |    errors.log.include.messages = false
connect_1  |    errors.retry.delay.max.ms = 60000
connect_1  |    errors.retry.timeout = 0
connect_1  |    errors.tolerance = none
connect_1  |    header.converter = null
connect_1  |    key.converter = null
connect_1  |    name = jdbc-source-connector
connect_1  |    tasks.max = 10
connect_1  |    transforms = []
connect_1  |    value.converter = null
connect_1  |  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:279)
connect_1  | [DEBUG] 2019-07-01 12:39:09.779 [DistributedHerder] JdbcSourceConnector - taskClass
connect_1  | [2019-07-01 12:39:09,779] ERROR Failed to reconfigure connector's tasks, retrying after backoff: (org.apache.kafka.connect.runtime.distributed.DistributedHerder:958)
connect_1  | java.lang.NullPointerException
connect_1  |    at org.apache.kafka.connect.runtime.Worker.connectorTaskConfigs(Worker.java:294)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnector(DistributedHerder.java:997)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnectorTasksWithRetry(DistributedHerder.java:950)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.access$900(DistributedHerder.java:110)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder$17$1.call(DistributedHerder.java:963)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder$17$1.call(DistributedHerder.java:960)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.tick(DistributedHerder.java:270)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:219)
connect_1  |    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
connect_1  |    at java.util.concurrent.FutureTask.run(FutureTask.java:266)
connect_1  |    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
connect_1  |    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
connect_1  |    at java.lang.Thread.run(Thread.java:745)
connect_1  | [2019-07-01 12:39:09,781] ERROR Unexpected error during connector task reconfiguration:  (org.apache.kafka.connect.runtime.distributed.DistributedHerder:969)
connect_1  | [2019-07-01 12:39:09,782] ERROR Task reconfiguration for jdbc-source-connector failed unexpectedly, this connector will not be properly reconfigured unless manually triggered. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:970)
connect_1  | [2019-07-01 12:39:10,032] INFO SourceConnectorConfig values:
connect_1  |    config.action.reload = restart
connect_1  |    connector.class = com.it.ibm.kafka.connectors.JdbcSourceConnector
connect_1  |    errors.log.enable = false
connect_1  |    errors.log.include.messages = false
connect_1  |    errors.retry.delay.max.ms = 60000
connect_1  |    errors.retry.timeout = 0
connect_1  |    errors.tolerance = none
connect_1  |    header.converter = null
connect_1  |    key.converter = null
connect_1  |    name = jdbc-source-connector
connect_1  |    tasks.max = 10
connect_1  |    transforms = []
connect_1  |    value.converter = null
connect_1  |  (org.apache.kafka.connect.runtime.SourceConnectorConfig:279)
connect_1  | [2019-07-01 12:39:10,032] INFO EnrichedConnectorConfig values:
connect_1  |    config.action.reload = restart
connect_1  |    connector.class = com.it.ibm.kafka.connectors.JdbcSourceConnector
connect_1  |    errors.log.enable = false
connect_1  |    errors.log.include.messages = false
connect_1  |    errors.retry.delay.max.ms = 60000
connect_1  |    errors.retry.timeout = 0
connect_1  |    errors.tolerance = none
connect_1  |    header.converter = null
connect_1  |    key.converter = null
connect_1  |    name = jdbc-source-connector
connect_1  |    tasks.max = 10
connect_1  |    transforms = []
connect_1  |    value.converter = null
connect_1  |  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:279)
connect_1  | [DEBUG] 2019-07-01 12:39:10.033 [DistributedHerder] JdbcSourceConnector - taskClass
connect_1  | [2019-07-01 12:39:10,033] ERROR Failed to reconfigure connector's tasks, retrying after backoff: (org.apache.kafka.connect.runtime.distributed.DistributedHerder:958)
connect_1  | java.lang.NullPointerException
connect_1  |    at org.apache.kafka.connect.runtime.Worker.connectorTaskConfigs(Worker.java:294)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnector(DistributedHerder.java:997)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnectorTasksWithRetry(DistributedHerder.java:950)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.access$900(DistributedHerder.java:110)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder$17$1.call(DistributedHerder.java:963)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder$17$1.call(DistributedHerder.java:960)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.tick(DistributedHerder.java:270)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:219)
connect_1  |    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
connect_1  |    at java.util.concurrent.FutureTask.run(FutureTask.java:266)
connect_1  |    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
connect_1  |    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
connect_1  |    at java.lang.Thread.run(Thread.java:745)
connect_1  | [2019-07-01 12:39:10,034] ERROR Unexpected error during connector task reconfiguration:  (org.apache.kafka.connect.runtime.distributed.DistributedHerder:969)
connect_1  | [2019-07-01 12:39:10,034] ERROR Task reconfiguration for jdbc-source-connector failed unexpectedly, this connector will not be properly reconfigured unless manually triggered. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:970)
connect_1  | [2019-07-01 12:39:10,283] INFO SourceConnectorConfig values:
connect_1  |    config.action.reload = restart
connect_1  |    connector.class = com.it.ibm.kafka.connectors.JdbcSourceConnector
connect_1  |    errors.log.enable = false
connect_1  |    errors.log.include.messages = false
connect_1  |    errors.retry.delay.max.ms = 60000
connect_1  |    errors.retry.timeout = 0
connect_1  |    errors.tolerance = none
connect_1  |    header.converter = null
connect_1  |    key.converter = null
connect_1  |    name = jdbc-source-connector
connect_1  |    tasks.max = 10
connect_1  |    transforms = []
connect_1  |    value.converter = null
connect_1  |  (org.apache.kafka.connect.runtime.SourceConnectorConfig:279)
connect_1  | [2019-07-01 12:39:10,284] INFO EnrichedConnectorConfig values:
connect_1  |    config.action.reload = restart
connect_1  |    connector.class = com.it.ibm.kafka.connectors.JdbcSourceConnector
connect_1  |    errors.log.enable = false
connect_1  |    errors.log.include.messages = false
connect_1  |    errors.retry.delay.max.ms = 60000
connect_1  |    errors.retry.timeout = 0
connect_1  |    errors.tolerance = none
connect_1  |    header.converter = null
connect_1  |    key.converter = null
connect_1  |    name = jdbc-source-connector
connect_1  |    tasks.max = 10
connect_1  |    transforms = []
connect_1  |    value.converter = null
connect_1  |  (org.apache.kafka.connect.runtime.ConnectorConfig$EnrichedConnectorConfig:279)
connect_1  | [DEBUG] 2019-07-01 12:39:10.284 [DistributedHerder] JdbcSourceConnector - taskClass
connect_1  | [2019-07-01 12:39:10,284] ERROR Failed to reconfigure connector's tasks, retrying after backoff: (org.apache.kafka.connect.runtime.distributed.DistributedHerder:958)
connect_1  | java.lang.NullPointerException
connect_1  |    at org.apache.kafka.connect.runtime.Worker.connectorTaskConfigs(Worker.java:294)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnector(DistributedHerder.java:997)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.reconfigureConnectorTasksWithRetry(DistributedHerder.java:950)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.access$900(DistributedHerder.java:110)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder$17$1.call(DistributedHerder.java:963)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder$17$1.call(DistributedHerder.java:960)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.tick(DistributedHerder.java:270)
connect_1  |    at org.apache.kafka.connect.runtime.distributed.DistributedHerder.run(DistributedHerder.java:219)
connect_1  |    at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511)
connect_1  |    at java.util.concurrent.FutureTask.run(FutureTask.java:266)
connect_1  |    at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
connect_1  |    at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
connect_1  |    at java.lang.Thread.run(Thread.java:745)
connect_1  | [2019-07-01 12:39:10,285] ERROR Unexpected error during connector task reconfiguration:  (org.apache.kafka.connect.runtime.distributed.DistributedHerder:969)
connect_1  | [2019-07-01 12:39:10,285] ERROR Task reconfiguration for jdbc-source-connector failed unexpectedly, this connector will not be properly reconfigured unless manually triggered. (org.apache.kafka.connect.runtime.distributed.DistributedHerder:970)
connect_1  | [2019-07-01 12:39:10,535] INFO SourceConnectorConfig values:
connect_1  |    config.action.reload = restart
connect_1  |    connector.class = com.it.ibm.kafka.connectors.JdbcSourceConnector
connect_1  |    errors.log.enable = false
connect_1  |    errors.log.include.messages = false
connect_1  |    errors.retry.delay.max.ms = 60000
connect_1  |    errors.retry.timeout = 0
connect_1  |    errors.tolerance = none
connect_1  |    header.converter = null
connect_1  |    key.converter = null
connect_1  |    name = jdbc-source-connector
connect_1  |    tasks.max = 10
connect_1  |    transforms = []
connect_1  |    value.converter = null
connect_1  |  (org.apache.kafka.connect.runtime.SourceConnectorConfig:279)
connect_1  | [2019-07-01 12:39:10,536] INFO EnrichedConnectorConfig values:
connect_1  |    config.action.reload = restart
connect_1  |    connector.class = com.it.ibm.kafka.connectors.JdbcSourceConnector
connect_1  |    errors.log.enable = false
connect_1  |





















































































































































































































































































































































